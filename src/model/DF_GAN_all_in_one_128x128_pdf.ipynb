{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DF_GAN_all_in_one_128x128_bn_g_block.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KFPeIf7l2vl",
        "outputId": "9171ad61-7db5-4d37-9299-f9cce62298fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        " !pip install fpdf2\n",
        " "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fpdf2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/28/08c70ff4dc9bb1b0d803432a0b89511bff9c53902b9c81c67f9473dd0d39/fpdf2-2.0.6-py2.py3-none-any.whl (71kB)\n",
            "\r\u001b[K     |████▌                           | 10kB 24.4MB/s eta 0:00:01\r\u001b[K     |█████████                       | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 40kB 2.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 71kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 2.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow<=8,>=4 in /usr/local/lib/python3.6/dist-packages (from fpdf2) (7.0.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from fpdf2) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fpdf2) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fpdf2) (1.15.0)\n",
            "Installing collected packages: fpdf2\n",
            "Successfully installed fpdf2-2.0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Y4QUbKZ37KZ",
        "outputId": "ba0d7a78-0e3f-4d1f-d405-d421d4783e6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget https://gitlab.com/didovgopoly/taste_it/-/raw/master/src/model/save_to_pdf.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-11 17:15:09--  https://gitlab.com/didovgopoly/taste_it/-/raw/master/src/model/save_to_pdf.py\n",
            "Resolving gitlab.com (gitlab.com)... 172.65.251.78, 2606:4700:90:0:f22e:fbec:5bed:a9b9\n",
            "Connecting to gitlab.com (gitlab.com)|172.65.251.78|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/plain]\n",
            "Saving to: ‘save_to_pdf.py’\n",
            "\n",
            "\rsave_to_pdf.py          [<=>                 ]       0  --.-KB/s               \rsave_to_pdf.py          [ <=>                ]   1.57K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-11-11 17:15:09 (40.0 MB/s) - ‘save_to_pdf.py’ saved [1608]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyBxzZ53Zx_3",
        "outputId": "ffecab60-341a-497b-a739-7a87dc605e95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Nov 11 17:15:09 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.32.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSTwg1N4NOEX",
        "outputId": "4269107b-63f0-40cd-816e-504c8ca65d5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from pathlib import Path\n",
        "import pickle\n",
        "import random\n",
        "from collections import OrderedDict\n",
        "import os\n",
        "\n",
        "from matplotlib.pyplot import imshow\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import torch.nn.functional as F\n",
        "import save_to_pdf\n",
        "import importlib\n",
        "from importlib import reload\n",
        "\n",
        "reload(save_to_pdf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'save_to_pdf' from '/content/save_to_pdf.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwL9TxOp0zoj",
        "outputId": "00f4be3c-e89b-491d-8d8c-be0c4c4b2951",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "drive_path = '/content/drive/My Drive/text2image'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9Tnj0SvNOEe",
        "outputId": "56857d4d-ea11-476e-acb6-5199cf46c882",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "os.makedirs('data', exist_ok=True)\n",
        "os.makedirs('data/embeddings', exist_ok=True)\n",
        "os.makedirs('/content/drive/My Drive/text2image/fake_images', exist_ok=True)\n",
        "os.makedirs('/content/drive/My Drive/text2image/fake_images/tmp', exist_ok=True)\n",
        "os.makedirs('/content/drive/My Drive/text2image/models', exist_ok=True)\n",
        "if not os.path.exists('GDriveDL.py'):\n",
        "    !wget https://raw.githubusercontent.com/matthuisman/gdrivedl/master/gdrivedl.py -O GDriveDL.py\n",
        "\n",
        "\n",
        "if not os.path.exists('data/eda_ru.zip'): \n",
        "    !python GDriveDL.py https://drive.google.com/file/d/1CNIbj8_OuxQD74zt6JU4BUI8ngctutl9/view?usp=sharing data\n",
        "    !unzip -q data/eda_ru.zip -d data\n",
        "# if not os.path.exists('df_gan.zip'):        \n",
        "#     !python GDriveDL.py https://drive.google.com/open?id=1KKAqwSbHd-_qMpOAjYdbBRCh4M-HbRTH .\n",
        "#     !unzip -q df_gan.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data/eda_ru.zip\n",
            "[==================================================] 1986.44MB/1986.44MB\n",
            "CPU times: user 11 s, sys: 6.61 s, total: 17.6 s\n",
            "Wall time: 2min 38s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gdypgitpViA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pDmIG_zNqdV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaKUwBDoNOEl"
      },
      "source": [
        "### 1) Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gp0WqatPNOEm"
      },
      "source": [
        "class RecipeDataset(data.Dataset):\n",
        "    def __init__(self, \n",
        "                 data_dir='data', \n",
        "                 csv_filename='eda_ru_filtered.csv',\n",
        "                 use_last_image=False,\n",
        "                 base_size=64,\n",
        "                 transform=None, target_transform=None):\n",
        "        self.transform = transform\n",
        "        self.norm = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "        self.target_transform = target_transform\n",
        "        \n",
        "        self.data_dir = Path(data_dir)\n",
        "        self.csv_filename = csv_filename\n",
        "        self.use_last_image = use_last_image\n",
        "        \n",
        "        self.data = pd.read_csv(self.data_dir / self.csv_filename, usecols=['id', 'images', 'title'])\n",
        "        self.ids = self.data['id'].values\n",
        "        self.images = self.data['images'].values\n",
        "        self.titles = self.data['title'].values\n",
        "        \n",
        "        self.embeddings = self.load_embeddings()\n",
        "\n",
        "    \n",
        "    def load_embeddings(self):\n",
        "\n",
        "        embeddings = []\n",
        "\n",
        "        for idx in self.ids:\n",
        "            title_emb = np.load(f'{self.data_dir}/embeddings/title/{idx}.npz')['arr_0']\n",
        "            ingredients_emb = np.load(f'{self.data_dir}/embeddings/ingredients/{idx}.npz')['arr_0']\n",
        "            # steps_emb = np.load(f'{self.data_dir}/embeddings/steps/{idx}.npz')['arr_0']\n",
        "            # all_recipe_emb = np.load(f'{self.data_dir}/embeddings/all_recipe/{idx}.npz')['arr_0']\n",
        "\n",
        "            embeddings.append(\n",
        "                np.concatenate([title_emb, ingredients_emb], axis=1)\n",
        "            )\n",
        "\n",
        "        return np.array(embeddings)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        #\n",
        "        image_pathes = self.images[idx].split('|')\n",
        "        if self.use_last_image:\n",
        "            img_path = image_pathes[-1]\n",
        "        else:\n",
        "            img_path = random.choice(image_pathes)\n",
        "       \n",
        "        # Загружаем изображение\n",
        "        img = Image.open(self.data_dir / img_path).convert('RGB')\n",
        "        width, height = img.size\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        imgs = []\n",
        "        imgs.append(self.norm(img))\n",
        "        \n",
        "        # ИСПРАВИТЬ - временно для того чтобы проверить работоспособность в целом\n",
        "        emb = self.embeddings[idx, :][0]\n",
        "        \n",
        "        return imgs, emb, self.titles[idx]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRpv0y1Xpc47"
      },
      "source": [
        "EMB_SIZE = 768 * 2\n",
        "\n",
        "class NetG(nn.Module):\n",
        "    def __init__(self, ngf=64, nz=100):\n",
        "        super(NetG, self).__init__()\n",
        "\n",
        "        # self.fc_embedding = nn.Linear(768, 256)\n",
        "\n",
        "        self.ngf = ngf\n",
        "\n",
        "        # layer1输入的是一个100x1x1的随机噪声, 输出尺寸(ngf*8)x4x4\n",
        "        self.fc = nn.Linear(nz, ngf*8*4*4)\n",
        "        self.block0 = G_Block(ngf * 8, ngf * 8)#4x4\n",
        "        self.block1 = G_Block(ngf * 8, ngf * 8)#4x4\n",
        "        self.block2 = G_Block(ngf * 8, ngf * 8)#8x8\n",
        "        self.block3 = G_Block(ngf * 8, ngf * 8)#16x16\n",
        "        self.block4 = G_Block(ngf * 8, ngf * 4)#32x32\n",
        "        # self.block5 = G_Block(ngf * 4, ngf * 2)#64x64\n",
        "        # self.block6 = G_Block(ngf * 2, ngf * 1)#128x128\n",
        "        self.block5 = G_Block(ngf * 4, ngf * 1)\n",
        "\n",
        "        self.conv_img = nn.Sequential(\n",
        "            nn.LeakyReLU(0.2,inplace=True),\n",
        "            nn.Conv2d(ngf, 3, 3, 1, 1),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, c):\n",
        "\n",
        "        # c = self.fc_embedding(c)\n",
        "\n",
        "        out = self.fc(x)\n",
        "        out = out.view(x.size(0), 8*self.ngf, 4, 4)\n",
        "        out = self.block0(out,c)\n",
        "\n",
        "        out = F.interpolate(out, scale_factor=2)\n",
        "        out = self.block1(out,c)\n",
        "\n",
        "        out = F.interpolate(out, scale_factor=2)\n",
        "        out = self.block2(out,c)\n",
        "\n",
        "        out = F.interpolate(out, scale_factor=2)\n",
        "        out = self.block3(out,c)\n",
        "\n",
        "        out = F.interpolate(out, scale_factor=2)\n",
        "        out = self.block4(out,c)\n",
        "\n",
        "        out = F.interpolate(out, scale_factor=2)\n",
        "        out = self.block5(out,c)\n",
        "        # out = F.interpolate(out, scale_factor=2)\n",
        "        # out = self.block6(out,c)\n",
        "\n",
        "        out = self.conv_img(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class G_Block(nn.Module):\n",
        "\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(G_Block, self).__init__()\n",
        "\n",
        "        self.learnable_sc = in_ch != out_ch \n",
        "        self.c1 = nn.Conv2d(in_ch, out_ch, 3, 1, 1)\n",
        "        self.c2 = nn.Conv2d(out_ch, out_ch, 3, 1, 1)\n",
        "        self.affine0 = affine(in_ch)\n",
        "        self.affine1 = affine(in_ch)\n",
        "        self.affine2 = affine(out_ch)\n",
        "        self.affine3 = affine(out_ch)\n",
        "        self.gamma = nn.Parameter(torch.zeros(1))\n",
        "        if self.learnable_sc:\n",
        "            self.c_sc = nn.Conv2d(in_ch,out_ch, 1, stride=1, padding=0)\n",
        "\n",
        "    def forward(self, x, y=None):\n",
        "        return self.shortcut(x) + self.gamma * self.residual(x, y)\n",
        "\n",
        "    def shortcut(self, x):\n",
        "        if self.learnable_sc:\n",
        "            x = self.c_sc(x)\n",
        "        return x\n",
        "\n",
        "    def residual(self, x, y=None):\n",
        "        h = self.affine0(x, y)\n",
        "        h = nn.LeakyReLU(0.2,inplace=True)(h)\n",
        "        h = self.affine1(h, y)\n",
        "        h = nn.LeakyReLU(0.2,inplace=True)(h)\n",
        "        h = self.c1(h)\n",
        "        \n",
        "        h = self.affine2(h, y)\n",
        "        h = nn.LeakyReLU(0.2,inplace=True)(h)\n",
        "        h = self.affine3(h, y)\n",
        "        h = nn.LeakyReLU(0.2,inplace=True)(h)\n",
        "        return self.c2(h)\n",
        "\n",
        "\n",
        "\n",
        "class affine(nn.Module):\n",
        "\n",
        "    def __init__(self, num_features):\n",
        "        super(affine, self).__init__()\n",
        "\n",
        "        self.fc_gamma = nn.Sequential(OrderedDict([\n",
        "            ('linear1',nn.Linear(EMB_SIZE, 256)),\n",
        "            ('relu1',nn.ReLU(inplace=True)),\n",
        "            ('linear2',nn.Linear(256, num_features)),\n",
        "            ]))\n",
        "        self.fc_beta = nn.Sequential(OrderedDict([\n",
        "            ('linear1',nn.Linear(EMB_SIZE, 256)),\n",
        "            ('relu1',nn.ReLU(inplace=True)),\n",
        "            ('linear2',nn.Linear(256, num_features)),\n",
        "            ]))\n",
        "        self._initialize()\n",
        "\n",
        "    def _initialize(self):\n",
        "        nn.init.zeros_(self.fc_gamma.linear2.weight.data)\n",
        "        nn.init.ones_(self.fc_gamma.linear2.bias.data)\n",
        "        nn.init.zeros_(self.fc_beta.linear2.weight.data)\n",
        "        nn.init.zeros_(self.fc_beta.linear2.bias.data)\n",
        "\n",
        "    def forward(self, x, y=None):\n",
        "\n",
        "        weight = self.fc_gamma(y)\n",
        "        bias = self.fc_beta(y)        \n",
        "\n",
        "        if weight.dim() == 1:\n",
        "            weight = weight.unsqueeze(0)\n",
        "        if bias.dim() == 1:\n",
        "            bias = bias.unsqueeze(0)\n",
        "\n",
        "        size = x.size()\n",
        "        weight = weight.unsqueeze(-1).unsqueeze(-1).expand(size)\n",
        "        bias = bias.unsqueeze(-1).unsqueeze(-1).expand(size)\n",
        "        return weight * x + bias\n",
        "\n",
        "\n",
        "class D_GET_LOGITS(nn.Module):\n",
        "    def __init__(self, ndf):\n",
        "        super(D_GET_LOGITS, self).__init__()\n",
        "        self.df_dim = ndf\n",
        "        # self.fc_embedding = nn.Linear(768, 256)\n",
        "\n",
        "        self.joint_conv = nn.Sequential(\n",
        "            nn.Conv2d(ndf * 16 + EMB_SIZE, ndf * 2, 3, 1, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2,inplace=True),\n",
        "            nn.Conv2d(ndf * 2, 1, 4, 1, 0, bias=False),\n",
        "        )\n",
        "\n",
        "    def forward(self, out, y):\n",
        "\n",
        "        # y = self.fc_embedding(y)\n",
        "        \n",
        "        y = y.view(-1, EMB_SIZE, 1, 1)\n",
        "        y = y.repeat(1, 1, 4, 4)\n",
        "        h_c_code = torch.cat((out, y), 1)\n",
        "        out = self.joint_conv(h_c_code)\n",
        "        return out\n",
        "\n",
        "\n",
        "class NetD(nn.Module):\n",
        "    def __init__(self, ndf):\n",
        "        super(NetD, self).__init__()\n",
        "\n",
        "        self.conv_img = nn.Conv2d(3, ndf, 3, 1, 1)#128\n",
        "        self.block0 = resD(ndf * 1, ndf * 2)#64\n",
        "        self.block1 = resD(ndf * 2, ndf * 4)#32\n",
        "        self.block2 = resD(ndf * 4, ndf * 8)#16\n",
        "        self.block3 = resD(ndf * 8, ndf * 16)#8\n",
        "        self.block4 = resD(ndf * 16, ndf * 16)#4\n",
        "        self.block5 = resD(ndf * 16, ndf * 16)#4\n",
        "\n",
        "        self.COND_DNET = D_GET_LOGITS(ndf)\n",
        "\n",
        "    def forward(self,x):\n",
        "        \n",
        "        out = self.conv_img(x)\n",
        "        out = self.block0(out)\n",
        "        out = self.block1(out)\n",
        "        out = self.block2(out)\n",
        "        out = self.block3(out)\n",
        "        out = self.block4(out)\n",
        "        # out = self.block5(out)\n",
        "\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class resD(nn.Module):\n",
        "    def __init__(self, fin, fout, downsample=True):\n",
        "        super().__init__()\n",
        "        self.downsample = downsample\n",
        "        self.learned_shortcut = (fin != fout)\n",
        "        self.conv_r = nn.Sequential(\n",
        "            nn.Conv2d(fin, fout, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            \n",
        "            nn.Conv2d(fout, fout, 3, 1, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "\n",
        "        self.conv_s = nn.Conv2d(fin,fout, 1, stride=1, padding=0)\n",
        "        self.gamma = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "    def forward(self, x, c=None):\n",
        "        return self.shortcut(x)+self.gamma*self.residual(x)\n",
        "\n",
        "    def shortcut(self, x):\n",
        "        if self.learned_shortcut:\n",
        "            x = self.conv_s(x)\n",
        "        if self.downsample:\n",
        "            return F.avg_pool2d(x, 2)\n",
        "        return x\n",
        "\n",
        "    def residual(self, x):\n",
        "        return self.conv_r(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoXn6sHUNOEw"
      },
      "source": [
        "## 2) Обучение"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uRiK_leNOEw",
        "outputId": "0f318c3c-ea25-4c93-9aa8-7b790f084539",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "seed = 100\n",
        "print(\"seed now is : \", seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device('cpu')\n",
        "cudnn.benchmark = True"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "seed now is :  100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swNJBDvTNOE0",
        "outputId": "3b164c41-6de6-4d71-95ef-db945dbe072b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfOT0k0lNOE2"
      },
      "source": [
        "#### Config:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZbbtxOjNOE3"
      },
      "source": [
        "config = {}\n",
        "\n",
        "config['MODEL_NAME'] = 'eda_ru_title_ingr_emb_128'\n",
        "\n",
        "config['CUDA'] = True\n",
        "config['WORKERS'] = 4\n",
        "\n",
        "config['loss'] = 'hinge'\n",
        "config['BASE_SIZE'] = 64\n",
        "\n",
        "# config['DATASET'] = {}\n",
        "# config['DATASET']['EMBEDDINGS_FILE'] = 'RuBERT_mean_embeddings_long'\n",
        "# config['DATASET']['EMBEDDINGS_TYPE'] = 'whole_recipe'\n",
        "\n",
        "\n",
        "config['IMAGE_SIZE'] = 128\n",
        "config['TRAIN'] = {}\n",
        "config['TRAIN']['BATCH_SIZE'] = 32 * 2\n",
        "config['TRAIN']['MAX_EPOCH'] = 512\n",
        "config['TRAIN']['SNAPSHOT_INTERVAL'] = 2000\n",
        "config['TRAIN']['DISCRIMINATOR_LR'] = 2e-4\n",
        "config['TRAIN']['GENERATOR_LR'] = 2e-4\n",
        "config['TRAIN']['ENCODER_LR'] = 2e-4\n",
        "# config['TRAIN']['RNN_GRAD_CLIP'] = 0.25\n",
        "# config['TRAIN']['FLAG'] = True\n",
        "# config['TRAIN']['NET_E'] = ''\n",
        "# config['TRAIN']['NET_G'] = ''\n",
        "# config['TRAIN']['B_NET_D'] = True\n",
        "config['TRAIN']['NF'] = 32\n",
        "config['TRAIN']['SMOOTH'] = {}\n",
        "config['TRAIN']['SMOOTH']['GAMMA1'] = 5.0\n",
        "config['TRAIN']['SMOOTH']['GAMMA1'] = 10.0\n",
        "config['TRAIN']['SMOOTH']['GAMMA1'] = 5.0\n",
        "config['TRAIN']['SMOOTH']['GAMMA1'] = 1.0\n",
        "\n",
        "config['GAN'] = {}\n",
        "config['GAN']['DF_DIM'] = 64\n",
        "config['GAN']['GF_DIM'] = 128\n",
        "config['GAN']['Z_DIM'] = 100\n",
        "config['GAN']['CONDITION_DIM'] = 100\n",
        "config['GAN']['R_NUM'] = 2\n",
        "config['GAN']['B_ATTENTION'] = True\n",
        "config['GAN']['B_DCGAN'] = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwP8-C08NOE6",
        "outputId": "c0faf8d0-4d7e-4288-e08c-a21c4e52a368",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# dataset and dataloader\n",
        "\n",
        "# image_transform = transforms.Compose([\n",
        "#     transforms.Resize(int(config['IMAGE_SIZE'] * 76 / 64)),\n",
        "#     transforms.RandomCrop(config['IMAGE_SIZE']),\n",
        "#     transforms.RandomHorizontalFlip()])\n",
        "\n",
        "image_transform = transforms.Compose([\n",
        "    transforms.Resize(int(config['IMAGE_SIZE']))\n",
        "    ])\n",
        "   \n",
        "dataset = RecipeDataset(transform=image_transform)\n",
        "\n",
        "print(len(dataset))\n",
        "assert dataset\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    dataset, batch_size=config['TRAIN']['BATCH_SIZE'], drop_last=True,\n",
        "    shuffle=True, num_workers=config['WORKERS'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30091\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I79bOCvpNOE8"
      },
      "source": [
        "def prepare_data(data):\n",
        "    imgs, embds, titles = data\n",
        "\n",
        "    real_imgs = []\n",
        "    for i in range(len(imgs)):\n",
        "        if config['CUDA']:\n",
        "            real_imgs.append(Variable(imgs[i]).cuda())\n",
        "        else:\n",
        "            real_imgs.append(Variable(imgs[i]))\n",
        "\n",
        "    if config['CUDA']:\n",
        "        embds = Variable(embds).cuda()\n",
        "    else:\n",
        "        embds = Variable(embds)\n",
        "\n",
        "    return [real_imgs, embds, titles]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pv0kIEAqNOE-"
      },
      "source": [
        "def train(dataloader, netG, netD, optimizerG, optimizerD, state_epoch, batch_size, device):\n",
        "    fake_images = Path(f'{drive_path}/fake_images')\n",
        "    fake_images.mkdir(exist_ok=True)\n",
        "    fake_images = fake_images / f'{config[\"MODEL_NAME\"]}'\n",
        "    fake_images.mkdir(exist_ok=True)\n",
        "    (fake_images / 'tmp').mkdir(exist_ok=True)\n",
        "\n",
        "    for epoch in range(state_epoch + 1, config['TRAIN']['MAX_EPOCH'] + 1):\n",
        "        for step, data in enumerate(dataloader, 0):\n",
        "    \n",
        "            imags, sent_emb, titles = prepare_data(data)\n",
        "#             hidden = text_encoder.init_hidden(batch_size)\n",
        "#             # words_embs: batch_size x nef x seq_len\n",
        "#             # sent_emb: batch_size x nef\n",
        "#             words_embs, sent_emb = text_encoder(captions, cap_lens, hidden)\n",
        "#             words_embs, sent_emb = words_embs.detach(), sent_emb.detach()\n",
        "\n",
        "            imgs=imags[0].to(device)\n",
        "            real_features = netD(imgs)\n",
        "            output = netD.COND_DNET(real_features, sent_emb)\n",
        "            errD_real = torch.nn.ReLU()(1.0 - output).mean()\n",
        "\n",
        "            output = netD.COND_DNET(real_features[:(batch_size - 1)], sent_emb[1:batch_size])\n",
        "            errD_mismatch = torch.nn.ReLU()(1.0 + output).mean()\n",
        "\n",
        "            # synthesize fake images\n",
        "            noise = torch.randn(batch_size, 100)\n",
        "            noise=noise.to(device)\n",
        "            fake = netG(noise,sent_emb)  \n",
        "            \n",
        "            # G does not need update with D\n",
        "            fake_features = netD(fake.detach()) \n",
        "\n",
        "            errD_fake = netD.COND_DNET(fake_features,sent_emb)\n",
        "            errD_fake = torch.nn.ReLU()(1.0 + errD_fake).mean()          \n",
        "\n",
        "            errD = errD_real + (errD_fake + errD_mismatch)/2.0\n",
        "            optimizerD.zero_grad()\n",
        "            optimizerG.zero_grad()\n",
        "            errD.backward()\n",
        "            optimizerD.step()\n",
        "\n",
        "            #MA-GP\n",
        "            interpolated = (imgs.data).requires_grad_(True)\n",
        "            sent_inter = (sent_emb.data).requires_grad_(True)\n",
        "            features = netD(interpolated)\n",
        "            out = netD.COND_DNET(features,sent_inter)\n",
        "            grads = torch.autograd.grad(outputs=out,\n",
        "                                    inputs=(interpolated,sent_inter),\n",
        "                                    grad_outputs=torch.ones(out.size()).cuda(),\n",
        "                                    retain_graph=True,\n",
        "                                    create_graph=True,\n",
        "                                    only_inputs=True)\n",
        "            grad0 = grads[0].view(grads[0].size(0), -1)\n",
        "            grad1 = grads[1].view(grads[1].size(0), -1)\n",
        "            grad = torch.cat((grad0,grad1),dim=1)                        \n",
        "            grad_l2norm = torch.sqrt(torch.sum(grad ** 2, dim=1))\n",
        "            d_loss_gp = torch.mean((grad_l2norm) ** 6)\n",
        "            d_loss = 2.0 * d_loss_gp\n",
        "            optimizerD.zero_grad()\n",
        "            optimizerG.zero_grad()\n",
        "            d_loss.backward()\n",
        "            optimizerD.step()\n",
        "            \n",
        "            # update G\n",
        "            features = netD(fake)\n",
        "            output = netD.COND_DNET(features,sent_emb)\n",
        "            errG = - output.mean()\n",
        "            optimizerG.zero_grad()\n",
        "            optimizerD.zero_grad()\n",
        "            errG.backward()\n",
        "            optimizerG.step()\n",
        "\n",
        "            if step % 200 == 0:\n",
        "                print('[%d/%d][%d/%d] Loss_D: %.3f Loss_G %.3f'\n",
        "                    % (epoch, config['TRAIN']['MAX_EPOCH'], step, len(dataloader), errD.item(), errG.item()))\n",
        "\n",
        "                save_to_pdf.save_pdf_images(fake.data, titles, str(fake_images), f'{config[\"MODEL_NAME\"]}_{epoch}_{step}')\n",
        "\n",
        "        if epoch % 1 == 0:\n",
        "            path_netG = f'{drive_path}/models/{config[\"MODEL_NAME\"]}_netG_{epoch}.pth' \n",
        "            path_netD = f'{drive_path}/models/{config[\"MODEL_NAME\"]}_netD_{epoch}.pth' \n",
        "            torch.save(netG.state_dict(), path_netG)\n",
        "            torch.save(netD.state_dict(), path_netD)      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40vbxeneNOFA"
      },
      "source": [
        "netG = NetG(ngf=config['TRAIN']['NF'], nz=100)\n",
        "netD = NetD(ndf=config['TRAIN']['NF'])\n",
        "state_epoch=0\n",
        "\n",
        "\n",
        "load_epoch = 20\n",
        "path_netG = f'{drive_path}/models/{config[\"MODEL_NAME\"]}_netG_{load_epoch}.pth' \n",
        "path_netD = f'{drive_path}/models/{config[\"MODEL_NAME\"]}_netD_{load_epoch}.pth' \n",
        "netG.load_state_dict(torch.load(path_netG))\n",
        "netD.load_state_dict(torch.load(path_netD))\n",
        "state_epoch = load_epoch\n",
        "\n",
        "\n",
        "netG.to(device)\n",
        "netD.to(device)\n",
        "optimizerG = torch.optim.Adam(netG.parameters(), lr=0.0001, betas=(0.0, 0.9))\n",
        "optimizerD = torch.optim.Adam(netD.parameters(), lr=0.0004, betas=(0.0, 0.9))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NILpHmENOFC",
        "outputId": "bf8048dd-22a5-4a4a-f553-390b73bba020",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train(dataloader, netG, netD, optimizerG, optimizerD, state_epoch, config['TRAIN']['BATCH_SIZE'], device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[21/512][0/470] Loss_D: 1.662 Loss_G 0.716\n",
            "[21/512][200/470] Loss_D: 1.708 Loss_G 0.746\n",
            "[21/512][400/470] Loss_D: 1.846 Loss_G 0.614\n",
            "[22/512][0/470] Loss_D: 1.824 Loss_G -0.674\n",
            "[22/512][200/470] Loss_D: 1.829 Loss_G -0.000\n",
            "[22/512][400/470] Loss_D: 1.724 Loss_G 0.836\n",
            "[23/512][0/470] Loss_D: 1.702 Loss_G 0.782\n",
            "[23/512][200/470] Loss_D: 2.034 Loss_G 1.465\n",
            "[23/512][400/470] Loss_D: 2.104 Loss_G 1.073\n",
            "[24/512][0/470] Loss_D: 1.764 Loss_G 0.858\n",
            "[24/512][200/470] Loss_D: 1.695 Loss_G 1.778\n",
            "[24/512][400/470] Loss_D: 2.007 Loss_G -0.063\n",
            "[25/512][0/470] Loss_D: 1.873 Loss_G 0.197\n",
            "[25/512][200/470] Loss_D: 1.743 Loss_G 0.450\n",
            "[25/512][400/470] Loss_D: 1.653 Loss_G 0.966\n",
            "[26/512][0/470] Loss_D: 1.729 Loss_G 0.635\n",
            "[26/512][200/470] Loss_D: 1.961 Loss_G 1.512\n",
            "[26/512][400/470] Loss_D: 1.664 Loss_G -0.623\n",
            "[27/512][0/470] Loss_D: 1.838 Loss_G 1.721\n",
            "[27/512][200/470] Loss_D: 1.766 Loss_G 0.700\n",
            "[27/512][400/470] Loss_D: 1.728 Loss_G 0.677\n",
            "[28/512][0/470] Loss_D: 2.656 Loss_G 1.150\n",
            "[28/512][200/470] Loss_D: 1.607 Loss_G 1.197\n",
            "[28/512][400/470] Loss_D: 1.977 Loss_G 0.706\n",
            "[29/512][0/470] Loss_D: 1.993 Loss_G 2.212\n",
            "[29/512][200/470] Loss_D: 1.559 Loss_G 1.340\n",
            "[29/512][400/470] Loss_D: 1.655 Loss_G 1.201\n",
            "[30/512][0/470] Loss_D: 2.151 Loss_G -0.705\n",
            "[30/512][200/470] Loss_D: 1.737 Loss_G 0.890\n",
            "[30/512][400/470] Loss_D: 1.874 Loss_G -0.460\n",
            "[31/512][0/470] Loss_D: 1.866 Loss_G 1.501\n",
            "[31/512][200/470] Loss_D: 1.629 Loss_G 0.895\n",
            "[31/512][400/470] Loss_D: 1.715 Loss_G 0.989\n",
            "[32/512][0/470] Loss_D: 1.614 Loss_G 1.166\n",
            "[32/512][200/470] Loss_D: 2.242 Loss_G 1.126\n",
            "[32/512][400/470] Loss_D: 1.745 Loss_G 0.808\n",
            "[33/512][0/470] Loss_D: 1.704 Loss_G -0.532\n",
            "[33/512][200/470] Loss_D: 1.714 Loss_G 0.949\n",
            "[33/512][400/470] Loss_D: 1.617 Loss_G 1.084\n",
            "[34/512][0/470] Loss_D: 1.613 Loss_G 0.131\n",
            "[34/512][200/470] Loss_D: 1.586 Loss_G 1.408\n",
            "[34/512][400/470] Loss_D: 2.320 Loss_G -0.915\n",
            "[35/512][0/470] Loss_D: 1.559 Loss_G -0.121\n",
            "[35/512][200/470] Loss_D: 1.838 Loss_G -0.740\n",
            "[35/512][400/470] Loss_D: 1.669 Loss_G 1.253\n",
            "[36/512][0/470] Loss_D: 1.709 Loss_G -0.325\n",
            "[36/512][200/470] Loss_D: 1.688 Loss_G -0.218\n",
            "[36/512][400/470] Loss_D: 2.151 Loss_G 1.250\n",
            "[37/512][0/470] Loss_D: 2.051 Loss_G 1.617\n",
            "[37/512][200/470] Loss_D: 1.936 Loss_G -0.313\n",
            "[37/512][400/470] Loss_D: 1.746 Loss_G -0.074\n",
            "[38/512][0/470] Loss_D: 1.502 Loss_G 0.799\n",
            "[38/512][200/470] Loss_D: 1.703 Loss_G 1.324\n",
            "[38/512][400/470] Loss_D: 1.869 Loss_G 1.473\n",
            "[39/512][0/470] Loss_D: 1.594 Loss_G 0.607\n",
            "[39/512][200/470] Loss_D: 1.574 Loss_G 0.765\n",
            "[39/512][400/470] Loss_D: 1.651 Loss_G 1.583\n",
            "[40/512][0/470] Loss_D: 1.986 Loss_G 1.394\n",
            "[40/512][200/470] Loss_D: 1.574 Loss_G 1.867\n",
            "[40/512][400/470] Loss_D: 1.840 Loss_G -0.452\n",
            "[41/512][0/470] Loss_D: 1.462 Loss_G 1.999\n",
            "saving to pdf failed. Saving to file\n",
            "[41/512][200/470] Loss_D: 1.860 Loss_G 1.406\n",
            "[41/512][400/470] Loss_D: 1.656 Loss_G -0.567\n",
            "[42/512][0/470] Loss_D: 1.661 Loss_G 1.505\n",
            "[42/512][200/470] Loss_D: 1.655 Loss_G 0.347\n",
            "[42/512][400/470] Loss_D: 1.851 Loss_G 1.274\n",
            "[43/512][0/470] Loss_D: 1.558 Loss_G 0.768\n",
            "[43/512][200/470] Loss_D: 1.830 Loss_G 1.795\n",
            "[43/512][400/470] Loss_D: 1.588 Loss_G 1.641\n",
            "[44/512][0/470] Loss_D: 1.543 Loss_G 0.936\n",
            "[44/512][200/470] Loss_D: 1.554 Loss_G 1.502\n",
            "[44/512][400/470] Loss_D: 1.552 Loss_G 1.138\n",
            "[45/512][0/470] Loss_D: 1.507 Loss_G 1.716\n",
            "[45/512][200/470] Loss_D: 1.647 Loss_G 0.843\n",
            "[45/512][400/470] Loss_D: 1.596 Loss_G 0.535\n",
            "[46/512][0/470] Loss_D: 1.829 Loss_G 1.250\n",
            "[46/512][200/470] Loss_D: 1.762 Loss_G 1.270\n",
            "[46/512][400/470] Loss_D: 1.609 Loss_G 0.139\n",
            "[47/512][0/470] Loss_D: 1.662 Loss_G 0.145\n",
            "[47/512][200/470] Loss_D: 1.564 Loss_G 0.298\n",
            "[47/512][400/470] Loss_D: 1.839 Loss_G 1.702\n",
            "[48/512][0/470] Loss_D: 1.577 Loss_G -0.370\n",
            "[48/512][200/470] Loss_D: 1.486 Loss_G 2.010\n",
            "[48/512][400/470] Loss_D: 1.431 Loss_G 1.389\n",
            "[49/512][0/470] Loss_D: 1.473 Loss_G 0.780\n",
            "[49/512][200/470] Loss_D: 1.500 Loss_G 0.208\n",
            "[49/512][400/470] Loss_D: 1.680 Loss_G 1.452\n",
            "[50/512][0/470] Loss_D: 1.532 Loss_G 0.270\n",
            "[50/512][200/470] Loss_D: 1.649 Loss_G 0.151\n",
            "[50/512][400/470] Loss_D: 1.624 Loss_G -0.297\n",
            "[51/512][0/470] Loss_D: 1.489 Loss_G 1.906\n",
            "[51/512][200/470] Loss_D: 1.421 Loss_G 1.267\n",
            "[51/512][400/470] Loss_D: 1.473 Loss_G 0.695\n",
            "[52/512][0/470] Loss_D: 1.804 Loss_G 1.618\n",
            "[52/512][200/470] Loss_D: 1.502 Loss_G 0.718\n",
            "[52/512][400/470] Loss_D: 1.719 Loss_G -0.235\n",
            "[53/512][0/470] Loss_D: 1.391 Loss_G 0.703\n",
            "[53/512][200/470] Loss_D: 1.641 Loss_G 0.224\n",
            "[53/512][400/470] Loss_D: 1.590 Loss_G 0.496\n",
            "[54/512][0/470] Loss_D: 1.522 Loss_G 0.550\n",
            "[54/512][200/470] Loss_D: 1.668 Loss_G 1.444\n",
            "[54/512][400/470] Loss_D: 1.487 Loss_G -0.368\n",
            "[55/512][0/470] Loss_D: 1.594 Loss_G 1.610\n",
            "[55/512][200/470] Loss_D: 1.426 Loss_G 2.150\n",
            "[55/512][400/470] Loss_D: 1.739 Loss_G -0.112\n",
            "[56/512][0/470] Loss_D: 1.613 Loss_G 0.534\n",
            "[56/512][200/470] Loss_D: 1.629 Loss_G 1.864\n",
            "[56/512][400/470] Loss_D: 1.625 Loss_G 0.044\n",
            "[57/512][0/470] Loss_D: 1.427 Loss_G 0.740\n",
            "[57/512][200/470] Loss_D: 1.524 Loss_G 2.258\n",
            "[57/512][400/470] Loss_D: 1.430 Loss_G 0.357\n",
            "[58/512][0/470] Loss_D: 1.445 Loss_G 2.181\n",
            "[58/512][200/470] Loss_D: 1.398 Loss_G 0.659\n",
            "[58/512][400/470] Loss_D: 1.450 Loss_G 1.663\n",
            "[59/512][0/470] Loss_D: 1.610 Loss_G 0.663\n",
            "[59/512][200/470] Loss_D: 1.475 Loss_G 0.553\n",
            "[59/512][400/470] Loss_D: 1.480 Loss_G 2.100\n",
            "[60/512][0/470] Loss_D: 1.477 Loss_G 2.115\n",
            "[60/512][200/470] Loss_D: 1.535 Loss_G 2.123\n",
            "[60/512][400/470] Loss_D: 1.485 Loss_G 1.924\n",
            "[61/512][0/470] Loss_D: 1.414 Loss_G 1.973\n",
            "[61/512][200/470] Loss_D: 1.486 Loss_G 1.765\n",
            "[61/512][400/470] Loss_D: 1.363 Loss_G 0.222\n",
            "[62/512][0/470] Loss_D: 1.664 Loss_G 1.994\n",
            "[62/512][200/470] Loss_D: 1.373 Loss_G 1.439\n",
            "[62/512][400/470] Loss_D: 1.482 Loss_G 0.394\n",
            "[63/512][0/470] Loss_D: 1.380 Loss_G 0.988\n",
            "[63/512][200/470] Loss_D: 1.440 Loss_G 1.781\n",
            "[63/512][400/470] Loss_D: 1.322 Loss_G 0.849\n",
            "[64/512][0/470] Loss_D: 1.368 Loss_G 2.345\n",
            "[64/512][200/470] Loss_D: 1.558 Loss_G 2.133\n",
            "saving to pdf failed. Saving to file\n",
            "[64/512][400/470] Loss_D: 1.406 Loss_G 0.654\n",
            "[65/512][0/470] Loss_D: 1.436 Loss_G 2.005\n",
            "[65/512][200/470] Loss_D: 1.688 Loss_G 0.095\n",
            "[65/512][400/470] Loss_D: 1.415 Loss_G 0.426\n",
            "[66/512][0/470] Loss_D: 1.412 Loss_G 0.672\n",
            "[66/512][200/470] Loss_D: 1.639 Loss_G -0.194\n",
            "[66/512][400/470] Loss_D: 1.269 Loss_G 1.661\n",
            "[67/512][0/470] Loss_D: 1.474 Loss_G 2.058\n",
            "[67/512][200/470] Loss_D: 1.429 Loss_G 0.339\n",
            "[67/512][400/470] Loss_D: 1.463 Loss_G 1.999\n",
            "[68/512][0/470] Loss_D: 1.391 Loss_G 2.123\n",
            "[68/512][200/470] Loss_D: 1.530 Loss_G 2.628\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_2_mal2rxRw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2CjVIWZaF0t"
      },
      "source": [
        "dataset[1][1][0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yx4w9KhOnxMu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
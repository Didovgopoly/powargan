{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StackGan_V2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AyM56ljryQK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ed40493-4eb2-4d58-ce55-6dd9233af1cb"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "from easydict import EasyDict as edict\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import torch.utils.data as data\n",
        "\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "import torchvision.utils as vutils\n",
        "import numpy as np\n",
        "import os\n",
        "import gc\n",
        "import time\n",
        "import random\n",
        "from PIL import Image, ImageFont, ImageDraw\n",
        "from copy import deepcopy\n",
        "\n",
        "from torch.utils.tensorboard import summary\n",
        "from torch.utils.tensorboard import FileWriter\n",
        "\n",
        "import save_to_pdf\n",
        "import importlib\n",
        "from importlib import reload\n",
        "\n",
        "reload(save_to_pdf)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'save_to_pdf' from '/content/save_to_pdf.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRfSDOxE4F9N",
        "outputId": "b2c68f3b-e0ff-4bad-fb23-eb50c274c480"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "drive_path = '/content/drive/My Drive/text2image'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZS51hw6u4HIZ",
        "outputId": "8d19880b-f531-4031-ac34-f9a9998b1a8e"
      },
      "source": [
        "!nvidia-smi\n",
        "!pip install -q fpdf2\n",
        "!wget -q https://gitlab.com/didovgopoly/taste_it/-/raw/master/src/model/save_to_pdf.py\n",
        "\n",
        "os.makedirs('data', exist_ok=True)\n",
        "os.makedirs('data/embeddings', exist_ok=True)\n",
        "os.makedirs('/content/drive/My Drive/text2image/fake_images', exist_ok=True)\n",
        "os.makedirs('/content/drive/My Drive/text2image/fake_images/tmp', exist_ok=True)\n",
        "os.makedirs('/content/drive/My Drive/text2image/models', exist_ok=True)\n",
        "if not os.path.exists('GDriveDL.py'):\n",
        "    !wget -q https://raw.githubusercontent.com/matthuisman/gdrivedl/master/gdrivedl.py -O GDriveDL.py\n",
        "\n",
        "\n",
        "if not os.path.exists('data/eda_ru.zip'): \n",
        "    !python GDriveDL.py https://drive.google.com/file/d/1CNIbj8_OuxQD74zt6JU4BUI8ngctutl9/view?usp=sharing data\n",
        "    !unzip -q data/eda_ru.zip -d data"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Nov 26 11:39:29 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.38       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    48W / 300W |      0MiB / 16130MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvOon38_roiN"
      },
      "source": [
        "__C = edict()\n",
        "cfg = __C\n",
        "\n",
        "# Dataset name: flowers, birds\n",
        "__C.DATASET_NAME = 'birds'\n",
        "__C.EMBEDDING_TYPE = 'cnn-rnn'\n",
        "__C.CONFIG_NAME = ''\n",
        "__C.DATA_DIR = ''\n",
        "\n",
        "__C.GPU_ID = '0'\n",
        "__C.CUDA = True\n",
        "\n",
        "__C.WORKERS = 6\n",
        "\n",
        "__C.TREE = edict()\n",
        "__C.TREE.BRANCH_NUM = 3\n",
        "__C.TREE.BASE_SIZE = 64\n",
        "\n",
        "\n",
        "# Test options\n",
        "__C.TEST = edict()\n",
        "__C.TEST.B_EXAMPLE = True\n",
        "__C.TEST.SAMPLE_NUM = 30000\n",
        "\n",
        "\n",
        "# Training options\n",
        "__C.TRAIN = edict()\n",
        "__C.TRAIN.BATCH_SIZE = 32 # 64\n",
        "__C.TRAIN.VIS_COUNT = 32 # 64\n",
        "__C.TRAIN.MAX_EPOCH = 600\n",
        "__C.TRAIN.SNAPSHOT_INTERVAL = 1000\n",
        "__C.TRAIN.DISCRIMINATOR_LR = 1e-4\n",
        "__C.TRAIN.GENERATOR_LR = 2e-4\n",
        "__C.TRAIN.FLAG = True\n",
        "__C.TRAIN.NET_G = ''\n",
        "__C.TRAIN.NET_D = ''\n",
        "\n",
        "__C.TRAIN.COEFF = edict()\n",
        "__C.TRAIN.COEFF.KL = 2.0\n",
        "__C.TRAIN.COEFF.UNCOND_LOSS = 0.0\n",
        "__C.TRAIN.COEFF.COLOR_LOSS = 0.0\n",
        "\n",
        "\n",
        "# Modal options\n",
        "__C.GAN = edict()\n",
        "__C.GAN.EMBEDDING_DIM = 128\n",
        "__C.GAN.DF_DIM = 64\n",
        "__C.GAN.GF_DIM = 64\n",
        "__C.GAN.Z_DIM = 100\n",
        "__C.GAN.NETWORK_TYPE = 'default'\n",
        "__C.GAN.R_NUM = 2\n",
        "__C.GAN.B_CONDITION = True\n",
        "\n",
        "__C.TEXT = edict()\n",
        "__C.TEXT.DIMENSION = 768 #1024"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6kYzWZUsFu0"
      },
      "source": [
        "class INCEPTION_V3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(INCEPTION_V3, self).__init__()\n",
        "        print('after constructor parent INCEPTION_V3')\n",
        "        self.model = models.inception_v3(pretrained=False, init_weights=False)\n",
        "        print('after models.inception_v3() call')\n",
        "        url = 'https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth'\n",
        "        # url = 'inception_v3_google-1a9a5a14.pth'\n",
        "        # print(next(model.parameters()).data)\n",
        "        print('start downloading inception')\n",
        "        state_dict = \\\n",
        "            model_zoo.load_url(url, map_location=lambda storage, loc: storage)\n",
        "        print('finish downloading inception')\n",
        "        self.model.load_state_dict(state_dict)\n",
        "\n",
        "        for param in self.model.parameters():\n",
        "            param.requires_grad = False\n",
        "        print('Load pretrained model from ', url)\n",
        "        # print(next(self.model.parameters()).data)\n",
        "        # print(self.model)\n",
        "\n",
        "    def forward(self, input):\n",
        "        # [-1.0, 1.0] --> [0, 1.0]\n",
        "        x = input * 0.5 + 0.5\n",
        "        # mean=[0.485, 0.456, 0.406] and std=[0.229, 0.224, 0.225]\n",
        "        # --> mean = 0, std = 1\n",
        "        x[:, 0] = (x[:, 0] - 0.485) / 0.229\n",
        "        x[:, 1] = (x[:, 1] - 0.456) / 0.224\n",
        "        x[:, 2] = (x[:, 2] - 0.406) / 0.225\n",
        "        #\n",
        "        # --> fixed-size input: batch x 3 x 299 x 299\n",
        "        x = nn.Upsample(size=(299, 299), mode='bilinear')(x)\n",
        "        # 299 x 299 x 3\n",
        "        x = self.model(x)\n",
        "        x = nn.Softmax()(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class GLU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GLU, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        nc = x.size(1)\n",
        "        assert nc % 2 == 0, 'channels dont divide 2!'\n",
        "        nc = int(nc/2)\n",
        "        return x[:, :nc] * F.sigmoid(x[:, nc:])\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes):\n",
        "    \"3x3 convolution with padding\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=1,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "\n",
        "# ############## G networks ################################################\n",
        "# Upsale the spatial size by a factor of 2\n",
        "def upBlock(in_planes, out_planes):\n",
        "    block = nn.Sequential(\n",
        "        nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "        conv3x3(in_planes, out_planes * 2),\n",
        "        nn.BatchNorm2d(out_planes * 2),\n",
        "        GLU()\n",
        "    )\n",
        "    return block\n",
        "\n",
        "\n",
        "# Keep the spatial size\n",
        "def Block3x3_relu(in_planes, out_planes):\n",
        "    block = nn.Sequential(\n",
        "        conv3x3(in_planes, out_planes * 2),\n",
        "        nn.BatchNorm2d(out_planes * 2),\n",
        "        GLU()\n",
        "    )\n",
        "    return block\n",
        "\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, channel_num):\n",
        "        super(ResBlock, self).__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            conv3x3(channel_num, channel_num * 2),\n",
        "            nn.BatchNorm2d(channel_num * 2),\n",
        "            GLU(),\n",
        "            conv3x3(channel_num, channel_num),\n",
        "            nn.BatchNorm2d(channel_num)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.block(x)\n",
        "        out += residual\n",
        "        return out\n",
        "\n",
        "\n",
        "class CA_NET(nn.Module):\n",
        "    # some code is modified from vae examples\n",
        "    # (https://github.com/pytorch/examples/blob/master/vae/main.py)\n",
        "    def __init__(self):\n",
        "        super(CA_NET, self).__init__()\n",
        "        self.t_dim = cfg.TEXT.DIMENSION\n",
        "        self.ef_dim = cfg.GAN.EMBEDDING_DIM\n",
        "        self.fc = nn.Linear(self.t_dim, self.ef_dim * 4, bias=True)\n",
        "        self.relu = GLU()\n",
        "\n",
        "    def encode(self, text_embedding):\n",
        "        x = self.relu(self.fc(text_embedding))\n",
        "        mu = x[:, :self.ef_dim]\n",
        "        logvar = x[:, self.ef_dim:]\n",
        "        return mu, logvar\n",
        "\n",
        "    def reparametrize(self, mu, logvar):\n",
        "        std = logvar.mul(0.5).exp_()\n",
        "        if cfg.CUDA:\n",
        "            eps = torch.cuda.FloatTensor(std.size()).normal_()\n",
        "        else:\n",
        "            eps = torch.FloatTensor(std.size()).normal_()\n",
        "        eps = Variable(eps)\n",
        "        return eps.mul(std).add_(mu)\n",
        "\n",
        "    def forward(self, text_embedding):\n",
        "        mu, logvar = self.encode(text_embedding)\n",
        "        c_code = self.reparametrize(mu, logvar)\n",
        "        return c_code, mu, logvar\n",
        "\n",
        "\n",
        "class INIT_STAGE_G(nn.Module):\n",
        "    def __init__(self, ngf):\n",
        "        super(INIT_STAGE_G, self).__init__()\n",
        "        self.gf_dim = ngf\n",
        "        if cfg.GAN.B_CONDITION:\n",
        "            self.in_dim = cfg.GAN.Z_DIM + cfg.GAN.EMBEDDING_DIM\n",
        "        else:\n",
        "            self.in_dim = cfg.GAN.Z_DIM\n",
        "        self.define_module()\n",
        "\n",
        "    def define_module(self):\n",
        "        in_dim = self.in_dim\n",
        "        ngf = self.gf_dim\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(in_dim, ngf * 4 * 4 * 2, bias=False),\n",
        "            nn.BatchNorm1d(ngf * 4 * 4 * 2),\n",
        "            GLU())\n",
        "\n",
        "\n",
        "        self.upsample1 = upBlock(ngf, ngf // 2)\n",
        "        self.upsample2 = upBlock(ngf // 2, ngf // 4)\n",
        "        self.upsample3 = upBlock(ngf // 4, ngf // 8)\n",
        "        self.upsample4 = upBlock(ngf // 8, ngf // 16)\n",
        "\n",
        "    def forward(self, z_code, c_code=None):\n",
        "        if cfg.GAN.B_CONDITION and c_code is not None:\n",
        "            in_code = torch.cat((c_code, z_code), 1)\n",
        "        else:\n",
        "            in_code = z_code\n",
        "        # state size 16ngf x 4 x 4\n",
        "        out_code = self.fc(in_code)\n",
        "        out_code = out_code.view(-1, self.gf_dim, 4, 4)\n",
        "        # state size 8ngf x 8 x 8\n",
        "        out_code = self.upsample1(out_code)\n",
        "        # state size 4ngf x 16 x 16\n",
        "        out_code = self.upsample2(out_code)\n",
        "        # state size 2ngf x 32 x 32\n",
        "        out_code = self.upsample3(out_code)\n",
        "        # state size ngf x 64 x 64\n",
        "        out_code = self.upsample4(out_code)\n",
        "\n",
        "        return out_code\n",
        "\n",
        "\n",
        "class NEXT_STAGE_G(nn.Module):\n",
        "    def __init__(self, ngf, num_residual=cfg.GAN.R_NUM):\n",
        "        super(NEXT_STAGE_G, self).__init__()\n",
        "        self.gf_dim = ngf\n",
        "        if cfg.GAN.B_CONDITION:\n",
        "            self.ef_dim = cfg.GAN.EMBEDDING_DIM\n",
        "        else:\n",
        "            self.ef_dim = cfg.GAN.Z_DIM\n",
        "        self.num_residual = num_residual\n",
        "        self.define_module()\n",
        "\n",
        "    def _make_layer(self, block, channel_num):\n",
        "        layers = []\n",
        "        for i in range(self.num_residual):\n",
        "            layers.append(block(channel_num))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def define_module(self):\n",
        "        ngf = self.gf_dim\n",
        "        efg = self.ef_dim\n",
        "\n",
        "        self.jointConv = Block3x3_relu(ngf + efg, ngf)\n",
        "        self.residual = self._make_layer(ResBlock, ngf)\n",
        "        self.upsample = upBlock(ngf, ngf // 2)\n",
        "\n",
        "    def forward(self, h_code, c_code):\n",
        "        s_size = h_code.size(2)\n",
        "        c_code = c_code.view(-1, self.ef_dim, 1, 1)\n",
        "        c_code = c_code.repeat(1, 1, s_size, s_size)\n",
        "        # state size (ngf+egf) x in_size x in_size\n",
        "        h_c_code = torch.cat((c_code, h_code), 1)\n",
        "        # state size ngf x in_size x in_size\n",
        "        out_code = self.jointConv(h_c_code)\n",
        "        out_code = self.residual(out_code)\n",
        "        # state size ngf/2 x 2in_size x 2in_size\n",
        "        out_code = self.upsample(out_code)\n",
        "\n",
        "        return out_code\n",
        "\n",
        "\n",
        "class GET_IMAGE_G(nn.Module):\n",
        "    def __init__(self, ngf):\n",
        "        super(GET_IMAGE_G, self).__init__()\n",
        "        self.gf_dim = ngf\n",
        "        self.img = nn.Sequential(\n",
        "            conv3x3(ngf, 3),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, h_code):\n",
        "        out_img = self.img(h_code)\n",
        "        return out_img\n",
        "\n",
        "\n",
        "class G_NET(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(G_NET, self).__init__()\n",
        "        self.gf_dim = cfg.GAN.GF_DIM\n",
        "        self.define_module()\n",
        "\n",
        "    def define_module(self):\n",
        "        if cfg.GAN.B_CONDITION:\n",
        "            self.ca_net = CA_NET()\n",
        "\n",
        "        if cfg.TREE.BRANCH_NUM > 0:\n",
        "            self.h_net1 = INIT_STAGE_G(self.gf_dim * 16)\n",
        "            self.img_net1 = GET_IMAGE_G(self.gf_dim)\n",
        "        if cfg.TREE.BRANCH_NUM > 1:\n",
        "            self.h_net2 = NEXT_STAGE_G(self.gf_dim)\n",
        "            self.img_net2 = GET_IMAGE_G(self.gf_dim // 2)\n",
        "        if cfg.TREE.BRANCH_NUM > 2:\n",
        "            self.h_net3 = NEXT_STAGE_G(self.gf_dim // 2)\n",
        "            self.img_net3 = GET_IMAGE_G(self.gf_dim // 4)\n",
        "        if cfg.TREE.BRANCH_NUM > 3: # Recommended structure (mainly limited by GPU memory), and not test yet\n",
        "            self.h_net4 = NEXT_STAGE_G(self.gf_dim // 4, num_residual=1)\n",
        "            self.img_net4 = GET_IMAGE_G(self.gf_dim // 8)\n",
        "        if cfg.TREE.BRANCH_NUM > 4:\n",
        "            self.h_net4 = NEXT_STAGE_G(self.gf_dim // 8, num_residual=1)\n",
        "            self.img_net4 = GET_IMAGE_G(self.gf_dim // 16)\n",
        "\n",
        "    def forward(self, z_code, text_embedding=None):\n",
        "        if cfg.GAN.B_CONDITION and text_embedding is not None:\n",
        "            c_code, mu, logvar = self.ca_net(text_embedding)\n",
        "        else:\n",
        "            c_code, mu, logvar = z_code, None, None\n",
        "        fake_imgs = []\n",
        "        if cfg.TREE.BRANCH_NUM > 0:\n",
        "            h_code1 = self.h_net1(z_code, c_code)\n",
        "            fake_img1 = self.img_net1(h_code1)\n",
        "            fake_imgs.append(fake_img1)\n",
        "        if cfg.TREE.BRANCH_NUM > 1:\n",
        "            h_code2 = self.h_net2(h_code1, c_code)\n",
        "            fake_img2 = self.img_net2(h_code2)\n",
        "            fake_imgs.append(fake_img2)\n",
        "        if cfg.TREE.BRANCH_NUM > 2:\n",
        "            h_code3 = self.h_net3(h_code2, c_code)\n",
        "            fake_img3 = self.img_net3(h_code3)\n",
        "            fake_imgs.append(fake_img3)\n",
        "        if cfg.TREE.BRANCH_NUM > 3:\n",
        "            h_code4 = self.h_net4(h_code3, c_code)\n",
        "            fake_img4 = self.img_net4(h_code4)\n",
        "            fake_imgs.append(fake_img4)\n",
        "\n",
        "        return fake_imgs, mu, logvar\n",
        "\n",
        "\n",
        "# ############## D networks ################################################\n",
        "def Block3x3_leakRelu(in_planes, out_planes):\n",
        "    block = nn.Sequential(\n",
        "        conv3x3(in_planes, out_planes),\n",
        "        nn.BatchNorm2d(out_planes),\n",
        "        nn.LeakyReLU(0.2, inplace=True)\n",
        "    )\n",
        "    return block\n",
        "\n",
        "\n",
        "# Downsale the spatial size by a factor of 2\n",
        "def downBlock(in_planes, out_planes):\n",
        "    block = nn.Sequential(\n",
        "        nn.Conv2d(in_planes, out_planes, 4, 2, 1, bias=False),\n",
        "        nn.BatchNorm2d(out_planes),\n",
        "        nn.LeakyReLU(0.2, inplace=True)\n",
        "    )\n",
        "    return block\n",
        "\n",
        "\n",
        "# Downsale the spatial size by a factor of 16\n",
        "def encode_image_by_16times(ndf):\n",
        "    encode_img = nn.Sequential(\n",
        "        # --> state size. ndf x in_size/2 x in_size/2\n",
        "        nn.Conv2d(3, ndf, 4, 2, 1, bias=False),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        # --> state size 2ndf x x in_size/4 x in_size/4\n",
        "        nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "        nn.BatchNorm2d(ndf * 2),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        # --> state size 4ndf x in_size/8 x in_size/8\n",
        "        nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "        nn.BatchNorm2d(ndf * 4),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        # --> state size 8ndf x in_size/16 x in_size/16\n",
        "        nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "        nn.BatchNorm2d(ndf * 8),\n",
        "        nn.LeakyReLU(0.2, inplace=True)\n",
        "    )\n",
        "    return encode_img\n",
        "\n",
        "# For 64 x 64 images\n",
        "class D_NET64(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(D_NET64, self).__init__()\n",
        "        self.df_dim = cfg.GAN.DF_DIM\n",
        "        self.ef_dim = cfg.GAN.EMBEDDING_DIM\n",
        "        self.define_module()\n",
        "\n",
        "    def define_module(self):\n",
        "        ndf = self.df_dim\n",
        "        efg = self.ef_dim\n",
        "        self.img_code_s16 = encode_image_by_16times(ndf)\n",
        "\n",
        "        self.logits = nn.Sequential(\n",
        "            nn.Conv2d(ndf * 8, 1, kernel_size=4, stride=4),\n",
        "            nn.Sigmoid())\n",
        "\n",
        "        if cfg.GAN.B_CONDITION:\n",
        "            self.jointConv = Block3x3_leakRelu(ndf * 8 + efg, ndf * 8)\n",
        "            self.uncond_logits = nn.Sequential(\n",
        "                nn.Conv2d(ndf * 8, 1, kernel_size=4, stride=4),\n",
        "                nn.Sigmoid())\n",
        "\n",
        "    def forward(self, x_var, c_code=None):\n",
        "        x_code = self.img_code_s16(x_var)\n",
        "\n",
        "        if cfg.GAN.B_CONDITION and c_code is not None:\n",
        "            # print(c_code.shape, self.ef_dim)\n",
        "            c_code = c_code.view(-1, self.ef_dim, 1, 1)\n",
        "            c_code = c_code.repeat(1, 1, 4, 4)\n",
        "            # state size (ngf+egf) x 4 x 4\n",
        "            # print(c_code.shape, x_code.shape)\n",
        "            h_c_code = torch.cat((c_code, x_code), 1)\n",
        "            # state size ngf x in_size x in_size\n",
        "            h_c_code = self.jointConv(h_c_code)\n",
        "        else:\n",
        "            h_c_code = x_code\n",
        "\n",
        "        output = self.logits(h_c_code)\n",
        "        if cfg.GAN.B_CONDITION:\n",
        "            out_uncond = self.uncond_logits(x_code)\n",
        "            return [output.view(-1), out_uncond.view(-1)]\n",
        "        else:\n",
        "            return [output.view(-1)]\n",
        "\n",
        "\n",
        "# For 128 x 128 images\n",
        "class D_NET128(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(D_NET128, self).__init__()\n",
        "        self.df_dim = cfg.GAN.DF_DIM\n",
        "        self.ef_dim = cfg.GAN.EMBEDDING_DIM\n",
        "        self.define_module()\n",
        "\n",
        "    def define_module(self):\n",
        "        ndf = self.df_dim\n",
        "        efg = self.ef_dim\n",
        "        self.img_code_s16 = encode_image_by_16times(ndf)\n",
        "        self.img_code_s32 = downBlock(ndf * 8, ndf * 16)\n",
        "        self.img_code_s32_1 = Block3x3_leakRelu(ndf * 16, ndf * 8)\n",
        "\n",
        "        self.logits = nn.Sequential(\n",
        "            nn.Conv2d(ndf * 8, 1, kernel_size=4, stride=4),\n",
        "            nn.Sigmoid())\n",
        "\n",
        "        if cfg.GAN.B_CONDITION:\n",
        "            self.jointConv = Block3x3_leakRelu(ndf * 8 + efg, ndf * 8)\n",
        "            self.uncond_logits = nn.Sequential(\n",
        "            nn.Conv2d(ndf * 8, 1, kernel_size=4, stride=4),\n",
        "            nn.Sigmoid())\n",
        "\n",
        "    def forward(self, x_var, c_code=None):\n",
        "        x_code = self.img_code_s16(x_var)\n",
        "        x_code = self.img_code_s32(x_code)\n",
        "        x_code = self.img_code_s32_1(x_code)\n",
        "\n",
        "        if cfg.GAN.B_CONDITION and c_code is not None:\n",
        "            c_code = c_code.view(-1, self.ef_dim, 1, 1)\n",
        "            c_code = c_code.repeat(1, 1, 4, 4)\n",
        "            # state size (ngf+egf) x 4 x 4\n",
        "            h_c_code = torch.cat((c_code, x_code), 1)\n",
        "            # state size ngf x in_size x in_size\n",
        "            h_c_code = self.jointConv(h_c_code)\n",
        "        else:\n",
        "            h_c_code = x_code\n",
        "\n",
        "        output = self.logits(h_c_code)\n",
        "        if cfg.GAN.B_CONDITION:\n",
        "            out_uncond = self.uncond_logits(x_code)\n",
        "            return [output.view(-1), out_uncond.view(-1)]\n",
        "        else:\n",
        "            return [output.view(-1)]\n",
        "\n",
        "\n",
        "# For 256 x 256 images\n",
        "class D_NET256(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(D_NET256, self).__init__()\n",
        "        self.df_dim = cfg.GAN.DF_DIM\n",
        "        self.ef_dim = cfg.GAN.EMBEDDING_DIM\n",
        "        self.define_module()\n",
        "\n",
        "    def define_module(self):\n",
        "        ndf = self.df_dim\n",
        "        efg = self.ef_dim\n",
        "        self.img_code_s16 = encode_image_by_16times(ndf)\n",
        "        self.img_code_s32 = downBlock(ndf * 8, ndf * 16)\n",
        "        self.img_code_s64 = downBlock(ndf * 16, ndf * 32)\n",
        "        self.img_code_s64_1 = Block3x3_leakRelu(ndf * 32, ndf * 16)\n",
        "        self.img_code_s64_2 = Block3x3_leakRelu(ndf * 16, ndf * 8)\n",
        "\n",
        "        self.logits = nn.Sequential(\n",
        "            nn.Conv2d(ndf * 8, 1, kernel_size=4, stride=4),\n",
        "            nn.Sigmoid())\n",
        "\n",
        "        if cfg.GAN.B_CONDITION:\n",
        "            self.jointConv = Block3x3_leakRelu(ndf * 8 + efg, ndf * 8)\n",
        "            self.uncond_logits = nn.Sequential(\n",
        "                nn.Conv2d(ndf * 8, 1, kernel_size=4, stride=4),\n",
        "                nn.Sigmoid())\n",
        "\n",
        "    def forward(self, x_var, c_code=None):\n",
        "        x_code = self.img_code_s16(x_var)\n",
        "        x_code = self.img_code_s32(x_code)\n",
        "        x_code = self.img_code_s64(x_code)\n",
        "        x_code = self.img_code_s64_1(x_code)\n",
        "        x_code = self.img_code_s64_2(x_code)\n",
        "\n",
        "        if cfg.GAN.B_CONDITION and c_code is not None:\n",
        "            c_code = c_code.view(-1, self.ef_dim, 1, 1)\n",
        "            c_code = c_code.repeat(1, 1, 4, 4)\n",
        "            # state size (ngf+egf) x 4 x 4\n",
        "            h_c_code = torch.cat((c_code, x_code), 1)\n",
        "            # state size ngf x in_size x in_size\n",
        "            h_c_code = self.jointConv(h_c_code)\n",
        "        else:\n",
        "            h_c_code = x_code\n",
        "\n",
        "        output = self.logits(h_c_code)\n",
        "        if cfg.GAN.B_CONDITION:\n",
        "            out_uncond = self.uncond_logits(x_code)\n",
        "            return [output.view(-1), out_uncond.view(-1)]\n",
        "        else:\n",
        "            return [output.view(-1)]\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3o4gqT7dsWKH"
      },
      "source": [
        "# ################## Shared functions ###################\n",
        "def compute_mean_covariance(img):\n",
        "    batch_size = img.size(0)\n",
        "    channel_num = img.size(1)\n",
        "    height = img.size(2)\n",
        "    width = img.size(3)\n",
        "    num_pixels = height * width\n",
        "\n",
        "    # batch_size * channel_num * 1 * 1\n",
        "    mu = img.mean(2, keepdim=True).mean(3, keepdim=True)\n",
        "\n",
        "    # batch_size * channel_num * num_pixels\n",
        "    img_hat = img - mu.expand_as(img)\n",
        "    img_hat = img_hat.view(batch_size, channel_num, num_pixels)\n",
        "    # batch_size * num_pixels * channel_num\n",
        "    img_hat_transpose = img_hat.transpose(1, 2)\n",
        "    # batch_size * channel_num * channel_num\n",
        "    covariance = torch.bmm(img_hat, img_hat_transpose)\n",
        "    covariance = covariance / num_pixels\n",
        "\n",
        "    return mu, covariance\n",
        "\n",
        "\n",
        "def KL_loss(mu, logvar):\n",
        "    # -0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
        "    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n",
        "    KLD = torch.mean(KLD_element).mul_(-0.5)\n",
        "    return KLD\n",
        "\n",
        "\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.orthogonal(m.weight.data, 1.0)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.normal_(1.0, 0.02)\n",
        "        m.bias.data.fill_(0)\n",
        "    elif classname.find('Linear') != -1:\n",
        "        nn.init.orthogonal(m.weight.data, 1.0)\n",
        "        if m.bias is not None:\n",
        "            m.bias.data.fill_(0.0)\n",
        "\n",
        "\n",
        "def load_params(model, new_param):\n",
        "    for p, new_p in zip(model.parameters(), new_param):\n",
        "        p.data.copy_(new_p)\n",
        "\n",
        "\n",
        "def copy_G_params(model):\n",
        "    flatten = deepcopy(list(p.data for p in model.parameters()))\n",
        "    return flatten\n",
        "\n",
        "\n",
        "def compute_inception_score(predictions, num_splits=1):\n",
        "    # print('predictions', predictions.shape)\n",
        "    scores = []\n",
        "    for i in range(num_splits):\n",
        "        istart = i * predictions.shape[0] // num_splits\n",
        "        iend = (i + 1) * predictions.shape[0] // num_splits\n",
        "        part = predictions[istart:iend, :]\n",
        "        kl = part * \\\n",
        "            (np.log(part) - np.log(np.expand_dims(np.mean(part, 0), 0)))\n",
        "        kl = np.mean(np.sum(kl, 1))\n",
        "        scores.append(np.exp(kl))\n",
        "    return np.mean(scores), np.std(scores)\n",
        "\n",
        "\n",
        "def negative_log_posterior_probability(predictions, num_splits=1):\n",
        "    # print('predictions', predictions.shape)\n",
        "    scores = []\n",
        "    for i in range(num_splits):\n",
        "        istart = i * predictions.shape[0] // num_splits\n",
        "        iend = (i + 1) * predictions.shape[0] // num_splits\n",
        "        part = predictions[istart:iend, :]\n",
        "        result = -1. * np.log(np.max(part, 1))\n",
        "        result = np.mean(result)\n",
        "        scores.append(result)\n",
        "    return np.mean(scores), np.std(scores)\n",
        "\n",
        "\n",
        "def load_network(gpus):\n",
        "    netG = G_NET().cuda()\n",
        "    netG.apply(weights_init)\n",
        "    # netG = torch.nn.DataParallel(netG, device_ids=gpus)\n",
        "    # print(netG)\n",
        "    print('netG loaded')\n",
        "\n",
        "    netsD = []\n",
        "    if cfg.TREE.BRANCH_NUM > 0:\n",
        "        netsD.append(D_NET64())\n",
        "    if cfg.TREE.BRANCH_NUM > 1:\n",
        "        netsD.append(D_NET128())\n",
        "    if cfg.TREE.BRANCH_NUM > 2:\n",
        "        netsD.append(D_NET256())\n",
        "    if cfg.TREE.BRANCH_NUM > 3:\n",
        "        netsD.append(D_NET512())\n",
        "    if cfg.TREE.BRANCH_NUM > 4:\n",
        "        netsD.append(D_NET1024())\n",
        "    # TODO: if cfg.TREE.BRANCH_NUM > 5:\n",
        "\n",
        "    for i in range(len(netsD)):\n",
        "        netsD[i].apply(weights_init)\n",
        "        # netsD[i] = torch.nn.DataParallel(netsD[i], device_ids=gpus)\n",
        "        # print(netsD[i])\n",
        "    print('# of netsD', len(netsD))\n",
        "\n",
        "    count = 0\n",
        "    if cfg.TRAIN.NET_G != '':\n",
        "        state_dict = torch.load(cfg.TRAIN.NET_G)\n",
        "        netG.load_state_dict(state_dict)\n",
        "        print('Load ', cfg.TRAIN.NET_G)\n",
        "\n",
        "        istart = cfg.TRAIN.NET_G.rfind('_') + 1\n",
        "        iend = cfg.TRAIN.NET_G.rfind('.')\n",
        "        count = cfg.TRAIN.NET_G[istart:iend]\n",
        "        count = int(count) + 1\n",
        "\n",
        "    if cfg.TRAIN.NET_D != '':\n",
        "        for i in range(len(netsD)):\n",
        "            print('Load %s_%d.pth' % (cfg.TRAIN.NET_D, i))\n",
        "            state_dict = torch.load('%s%d.pth' % (cfg.TRAIN.NET_D, i))\n",
        "            netsD[i].load_state_dict(state_dict)\n",
        "    print('inception_model creation')\n",
        "    inception_model = INCEPTION_V3()\n",
        "\n",
        "    if cfg.CUDA:\n",
        "        netG.cuda()\n",
        "        for i in range(len(netsD)):\n",
        "            netsD[i].cuda()\n",
        "        inception_model = inception_model.cuda()\n",
        "    inception_model.eval()\n",
        "    print('all models on cuda')\n",
        "\n",
        "    return netG, netsD, len(netsD), inception_model, count\n",
        "\n",
        "\n",
        "def define_optimizers(netG, netsD):\n",
        "    optimizersD = []\n",
        "    num_Ds = len(netsD)\n",
        "    for i in range(num_Ds):\n",
        "        opt = optim.Adam(netsD[i].parameters(),\n",
        "                         lr=cfg.TRAIN.DISCRIMINATOR_LR,\n",
        "                         betas=(0.5, 0.999))\n",
        "        optimizersD.append(opt)\n",
        "\n",
        "    # G_opt_paras = []\n",
        "    # for p in netG.parameters():\n",
        "    #     if p.requires_grad:\n",
        "    #         G_opt_paras.append(p)\n",
        "    optimizerG = optim.Adam(netG.parameters(),\n",
        "                            lr=cfg.TRAIN.GENERATOR_LR,\n",
        "                            betas=(0.5, 0.999))\n",
        "    return optimizerG, optimizersD\n",
        "\n",
        "\n",
        "def save_model(netG, avg_param_G, netsD, epoch, model_dir):\n",
        "    load_params(netG, avg_param_G)\n",
        "    torch.save(\n",
        "        netG.state_dict(),\n",
        "        '%s/netG_%d.pth' % (model_dir, epoch))\n",
        "    for i in range(len(netsD)):\n",
        "        netD = netsD[i]\n",
        "        torch.save(\n",
        "            netD.state_dict(),\n",
        "            '%s/netD%d.pth' % (model_dir, i))\n",
        "    print('Save G/Ds models.')\n",
        "\n",
        "\n",
        "def save_img_results(imgs_tcpu, fake_imgs, num_imgs,\n",
        "                     count, image_dir, titles):\n",
        "    num = cfg.TRAIN.VIS_COUNT\n",
        "\n",
        "    # The range of real_img (i.e., self.imgs_tcpu[i][0:num])\n",
        "    # is changed to [0, 1] by function vutils.save_image\n",
        "    real_img = imgs_tcpu[-1][0:num]\n",
        "    vutils.save_image(\n",
        "        real_img, '%s/real_samples.png' % (image_dir),\n",
        "        normalize=True)\n",
        "    real_img_set = vutils.make_grid(real_img).numpy()\n",
        "    real_img_set = np.transpose(real_img_set, (1, 2, 0))\n",
        "    real_img_set = real_img_set * 255\n",
        "    real_img_set = real_img_set.astype(np.uint8)\n",
        "    # sup_real_img = summary.image('real_img', real_img_set)\n",
        "    # summary_writer.add_summary(sup_real_img, count)\n",
        "\n",
        "    for i in range(num_imgs):\n",
        "        fake_img = fake_imgs[i][0:num]\n",
        "        # The range of fake_img.data (i.e., self.fake_imgs[i][0:num])\n",
        "        # is still [-1. 1]...\n",
        "        # vutils.save_image(\n",
        "        #     fake_img.data, '%s/count_%09d_fake_samples%d.png' %\n",
        "        #     (image_dir, count, i), normalize=True)\n",
        "        \n",
        "        save_to_pdf.save_pdf_images(fake_img.data, titles, image_dir, 'count_%09d_fake_samples%d' % (count, i))\n",
        "\n",
        "        # fake_img_set = vutils.make_grid(fake_img.data).cpu().numpy()\n",
        "\n",
        "        # fake_img_set = np.transpose(fake_img_set, (1, 2, 0))\n",
        "        # fake_img_set = (fake_img_set + 1) * 255 / 2\n",
        "        # fake_img_set = fake_img_set.astype(np.uint8)\n",
        "\n",
        "        # sup_fake_img = summary.image('fake_img%d' % i, fake_img_set)\n",
        "        # summary_writer.add_summary(sup_fake_img, count)\n",
        "        # summary_writer.flush()\n",
        "\n",
        "\n",
        "def mkdir_p(path):\n",
        "    try:\n",
        "        os.makedirs(path, exist_ok=True)\n",
        "    except OSError as exc:  # Python >2.5\n",
        "        if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
        "            pass\n",
        "        else:\n",
        "            raise"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_by6BNdlt1Zq"
      },
      "source": [
        "# ################# Text to image task############################ #\n",
        "class condGANTrainer(object):\n",
        "    def __init__(self, output_dir, data_loader, imsize):\n",
        "        if cfg.TRAIN.FLAG:\n",
        "            self.model_dir = os.path.join(output_dir, 'Model')\n",
        "            self.image_dir = os.path.join(output_dir, 'Image')\n",
        "            self.log_dir = os.path.join(output_dir, 'Log')\n",
        "            mkdir_p(self.model_dir)\n",
        "            mkdir_p(self.image_dir)\n",
        "            mkdir_p(self.log_dir)\n",
        "            self.summary_writer = FileWriter(self.log_dir)\n",
        "\n",
        "        s_gpus = cfg.GPU_ID.split(',')\n",
        "        self.gpus = [int(ix) for ix in s_gpus]\n",
        "        self.num_gpus = len(self.gpus)\n",
        "        torch.cuda.set_device(-1)\n",
        "        cudnn.benchmark = True\n",
        "\n",
        "        self.batch_size = cfg.TRAIN.BATCH_SIZE * self.num_gpus\n",
        "        self.max_epoch = cfg.TRAIN.MAX_EPOCH\n",
        "        self.snapshot_interval = cfg.TRAIN.SNAPSHOT_INTERVAL\n",
        "\n",
        "        self.data_loader = data_loader\n",
        "        self.num_batches = len(self.data_loader)\n",
        "\n",
        "    def prepare_data(self, data):\n",
        "        imgs, w_imgs, t_embedding, title = data\n",
        "\n",
        "        real_vimgs, wrong_vimgs = [], []\n",
        "        if cfg.CUDA:\n",
        "            vembedding = Variable(t_embedding).cuda()\n",
        "        else:\n",
        "            vembedding = Variable(t_embedding)\n",
        "        for i in range(self.num_Ds):\n",
        "            if cfg.CUDA:\n",
        "                real_vimgs.append(Variable(imgs[i]).cuda())\n",
        "                wrong_vimgs.append(Variable(w_imgs[i]).cuda())\n",
        "            else:\n",
        "                real_vimgs.append(Variable(imgs[i]))\n",
        "                wrong_vimgs.append(Variable(w_imgs[i]))\n",
        "        return imgs, real_vimgs, wrong_vimgs, vembedding, title\n",
        "\n",
        "    def train_Dnet(self, idx, count):\n",
        "        flag = count % 100\n",
        "        batch_size = self.real_imgs[0].size(0)\n",
        "        criterion, mu = self.criterion, self.mu\n",
        "\n",
        "        netD, optD = self.netsD[idx], self.optimizersD[idx]\n",
        "        real_imgs = self.real_imgs[idx]\n",
        "        wrong_imgs = self.wrong_imgs[idx]\n",
        "        fake_imgs = self.fake_imgs[idx]\n",
        "        #\n",
        "        netD.zero_grad()\n",
        "        # Forward\n",
        "        real_labels = self.real_labels[:batch_size]\n",
        "        fake_labels = self.fake_labels[:batch_size]\n",
        "        # for real\n",
        "        real_logits = netD(real_imgs, mu.detach())\n",
        "        wrong_logits = netD(wrong_imgs, mu.detach())\n",
        "        fake_logits = netD(fake_imgs.detach(), mu.detach())\n",
        "        #\n",
        "        errD_real = criterion(real_logits[0], real_labels)\n",
        "        errD_wrong = criterion(wrong_logits[0], fake_labels)\n",
        "        errD_fake = criterion(fake_logits[0], fake_labels)\n",
        "        if len(real_logits) > 1 and cfg.TRAIN.COEFF.UNCOND_LOSS > 0:\n",
        "            errD_real_uncond = cfg.TRAIN.COEFF.UNCOND_LOSS * \\\n",
        "                criterion(real_logits[1], real_labels)\n",
        "            errD_wrong_uncond = cfg.TRAIN.COEFF.UNCOND_LOSS * \\\n",
        "                criterion(wrong_logits[1], real_labels)\n",
        "            errD_fake_uncond = cfg.TRAIN.COEFF.UNCOND_LOSS * \\\n",
        "                criterion(fake_logits[1], fake_labels)\n",
        "            #\n",
        "            errD_real = errD_real + errD_real_uncond\n",
        "            errD_wrong = errD_wrong + errD_wrong_uncond\n",
        "            errD_fake = errD_fake + errD_fake_uncond\n",
        "            #\n",
        "            errD = errD_real + errD_wrong + errD_fake\n",
        "        else:\n",
        "            errD = errD_real + 0.5 * (errD_wrong + errD_fake)\n",
        "        # backward\n",
        "        errD.backward()\n",
        "        # update parameters\n",
        "        optD.step()\n",
        "        # log\n",
        "        if flag == 0:\n",
        "            summary_D = summary.scalar('D_loss%d' % idx, errD.data)\n",
        "            self.summary_writer.add_summary(summary_D, count)\n",
        "        return errD\n",
        "\n",
        "    def train_Gnet(self, count):\n",
        "        self.netG.zero_grad()\n",
        "        errG_total = 0\n",
        "        flag = count % 100\n",
        "        batch_size = self.real_imgs[0].size(0)\n",
        "        criterion, mu, logvar = self.criterion, self.mu, self.logvar\n",
        "        real_labels = self.real_labels[:batch_size]\n",
        "        for i in range(self.num_Ds):\n",
        "            outputs = self.netsD[i](self.fake_imgs[i], mu)\n",
        "            errG = criterion(outputs[0], real_labels)\n",
        "            if len(outputs) > 1 and cfg.TRAIN.COEFF.UNCOND_LOSS > 0:\n",
        "                errG_patch = cfg.TRAIN.COEFF.UNCOND_LOSS *\\\n",
        "                    criterion(outputs[1], real_labels)\n",
        "                errG = errG + errG_patch\n",
        "            errG_total = errG_total + errG\n",
        "            if flag == 0:\n",
        "                summary_D = summary.scalar('G_loss%d' % i, errG.data)\n",
        "                self.summary_writer.add_summary(summary_D, count)\n",
        "\n",
        "        # Compute color consistency losses\n",
        "        if cfg.TRAIN.COEFF.COLOR_LOSS > 0:\n",
        "            if self.num_Ds > 1:\n",
        "                mu1, covariance1 = compute_mean_covariance(self.fake_imgs[-1])\n",
        "                mu2, covariance2 = \\\n",
        "                    compute_mean_covariance(self.fake_imgs[-2].detach())\n",
        "                like_mu2 = cfg.TRAIN.COEFF.COLOR_LOSS * nn.MSELoss()(mu1, mu2)\n",
        "                like_cov2 = cfg.TRAIN.COEFF.COLOR_LOSS * 5 * \\\n",
        "                    nn.MSELoss()(covariance1, covariance2)\n",
        "                errG_total = errG_total + like_mu2 + like_cov2\n",
        "                if flag == 0:\n",
        "                    sum_mu = summary.scalar('G_like_mu2', like_mu2.data)\n",
        "                    self.summary_writer.add_summary(sum_mu, count)\n",
        "                    sum_cov = summary.scalar('G_like_cov2', like_cov2.data)\n",
        "                    self.summary_writer.add_summary(sum_cov, count)\n",
        "            if self.num_Ds > 2:\n",
        "                mu1, covariance1 = compute_mean_covariance(self.fake_imgs)\n",
        "                mu2, covariance2 = \\\n",
        "                    compute_mean_covariance(self.fake_imgs[-3].detach())\n",
        "                like_mu1 = cfg.TRAIN.COEFF.COLOR_LOSS * nn.MSELoss()(mu1, mu2)\n",
        "                like_cov1 = cfg.TRAIN.COEFF.COLOR_LOSS * 5 * \\\n",
        "                    nn.MSELoss()(covariance1, covariance2)\n",
        "                errG_total = errG_total + like_mu1 + like_cov1\n",
        "                if flag == 0:\n",
        "                    sum_mu = summary.scalar('G_like_mu1', like_mu1.data)\n",
        "                    self.summary_writer.add_summary(sum_mu, count)\n",
        "                    sum_cov = summary.scalar('G_like_cov1', like_cov1.data)\n",
        "                    self.summary_writer.add_summary(sum_cov, count)\n",
        "\n",
        "        kl_loss = KL_loss(mu, logvar) * cfg.TRAIN.COEFF.KL\n",
        "        errG_total = errG_total + kl_loss\n",
        "        errG_total.backward()\n",
        "        self.optimizerG.step()\n",
        "        return kl_loss, errG_total\n",
        "\n",
        "    def train(self):\n",
        "        self.netG, self.netsD, self.num_Ds,\\\n",
        "            self.inception_model, start_count = load_network(self.gpus)\n",
        "        avg_param_G = copy_G_params(self.netG)\n",
        "\n",
        "        self.optimizerG, self.optimizersD = \\\n",
        "            define_optimizers(self.netG, self.netsD)\n",
        "\n",
        "        self.criterion = nn.BCELoss()\n",
        "\n",
        "        self.real_labels = \\\n",
        "            Variable(torch.FloatTensor(self.batch_size).fill_(1))\n",
        "        self.fake_labels = \\\n",
        "            Variable(torch.FloatTensor(self.batch_size).fill_(0))\n",
        "\n",
        "        self.gradient_one = torch.FloatTensor([1.0])\n",
        "        self.gradient_half = torch.FloatTensor([0.5])\n",
        "\n",
        "        nz = cfg.GAN.Z_DIM\n",
        "        noise = Variable(torch.FloatTensor(self.batch_size, nz))\n",
        "        fixed_noise = \\\n",
        "            Variable(torch.FloatTensor(self.batch_size, nz).normal_(0, 1))\n",
        "\n",
        "        if cfg.CUDA:\n",
        "            self.criterion.cuda()\n",
        "            self.real_labels = self.real_labels.cuda()\n",
        "            self.fake_labels = self.fake_labels.cuda()\n",
        "            self.gradient_one = self.gradient_one.cuda()\n",
        "            self.gradient_half = self.gradient_half.cuda()\n",
        "            noise, fixed_noise = noise.cuda(), fixed_noise.cuda()\n",
        "\n",
        "        predictions = []\n",
        "        count = start_count\n",
        "        start_epoch = start_count // (self.num_batches)\n",
        "        for epoch in range(start_epoch, self.max_epoch):\n",
        "            start_t = time.time()\n",
        "\n",
        "            for step, data in enumerate(self.data_loader, 0):\n",
        "                #######################################################\n",
        "                # (0) Prepare training data\n",
        "                ######################################################\n",
        "                self.imgs_tcpu, self.real_imgs, self.wrong_imgs, \\\n",
        "                    self.txt_embedding, titles = self.prepare_data(data)\n",
        "\n",
        "                #######################################################\n",
        "                # (1) Generate fake images\n",
        "                ######################################################\n",
        "                noise.data.normal_(0, 1)\n",
        "                self.fake_imgs, self.mu, self.logvar = \\\n",
        "                    self.netG(noise, self.txt_embedding)\n",
        "\n",
        "                #######################################################\n",
        "                # (2) Update D network\n",
        "                ######################################################\n",
        "                errD_total = 0\n",
        "                for i in range(self.num_Ds):\n",
        "                    errD = self.train_Dnet(i, count)\n",
        "                    errD_total += errD\n",
        "\n",
        "                #######################################################\n",
        "                # (3) Update G network: maximize log(D(G(z)))\n",
        "                ######################################################\n",
        "                kl_loss, errG_total = self.train_Gnet(count)\n",
        "                for p, avg_p in zip(self.netG.parameters(), avg_param_G):\n",
        "                    avg_p.mul_(0.999).add_(0.001, p.data)\n",
        "\n",
        "                # for inception score\n",
        "                pred = self.inception_model(self.fake_imgs[-1].detach())\n",
        "                predictions.append(pred.data.cpu().numpy())\n",
        "\n",
        "                if count % 100 == 0:\n",
        "                    summary_D = summary.scalar('D_loss', errD_total.data)\n",
        "                    summary_G = summary.scalar('G_loss', errG_total.data)\n",
        "                    summary_KL = summary.scalar('KL_loss', kl_loss.data)\n",
        "                    self.summary_writer.add_summary(summary_D, count)\n",
        "                    self.summary_writer.add_summary(summary_G, count)\n",
        "                    self.summary_writer.add_summary(summary_KL, count)\n",
        "\n",
        "                count = count + 1\n",
        "\n",
        "                if count % cfg.TRAIN.SNAPSHOT_INTERVAL == 0:\n",
        "                    save_model(self.netG, avg_param_G, self.netsD, count, self.model_dir)\n",
        "                    # Save images\n",
        "                    backup_para = copy_G_params(self.netG)\n",
        "                    load_params(self.netG, avg_param_G)\n",
        "                    #\n",
        "                    self.fake_imgs, _, _ = \\\n",
        "                        self.netG(fixed_noise, self.txt_embedding)\n",
        "                    save_img_results(self.imgs_tcpu, self.fake_imgs, self.num_Ds,\n",
        "                                     count, self.image_dir, titles)\n",
        "                    #\n",
        "                    load_params(self.netG, backup_para)\n",
        "\n",
        "                    # Compute inception score\n",
        "                    if len(predictions) > 500:\n",
        "                        predictions = np.concatenate(predictions, 0)\n",
        "                        mean, std = compute_inception_score(predictions, 10)\n",
        "                        # print('mean:', mean, 'std', std)\n",
        "                        m_incep = summary.scalar('Inception_mean', mean)\n",
        "                        self.summary_writer.add_summary(m_incep, count)\n",
        "                        #\n",
        "                        mean_nlpp, std_nlpp = \\\n",
        "                            negative_log_posterior_probability(predictions, 10)\n",
        "                        m_nlpp = summary.scalar('NLPP_mean', mean_nlpp)\n",
        "                        self.summary_writer.add_summary(m_nlpp, count)\n",
        "                        #\n",
        "                        predictions = []\n",
        "\n",
        "            end_t = time.time()\n",
        "            print('''[%d/%d][%d] Loss_D: %.2f Loss_G: %.2f Loss_KL: %.2f Time: %.2fs'''  # D(real): %.4f D(wrong):%.4f  D(fake) %.4f\n",
        "                  % (epoch, self.max_epoch, self.num_batches,\n",
        "                     errD_total.data, errG_total.data,\n",
        "                     kl_loss.data, end_t - start_t))\n",
        "\n",
        "        save_model(self.netG, avg_param_G, self.netsD, count, self.model_dir)\n",
        "        self.summary_writer.close()\n",
        "\n",
        "    def save_superimages(self, images_list, filenames,\n",
        "                         save_dir, split_dir, imsize):\n",
        "        batch_size = images_list[0].size(0)\n",
        "        num_sentences = len(images_list)\n",
        "        for i in range(batch_size):\n",
        "            s_tmp = '%s/super/%s/%s' %\\\n",
        "                (save_dir, split_dir, filenames[i])\n",
        "            folder = s_tmp[:s_tmp.rfind('/')]\n",
        "            if not os.path.isdir(folder):\n",
        "                print('Make a new folder: ', folder)\n",
        "                mkdir_p(folder)\n",
        "            #\n",
        "            savename = '%s_%d.png' % (s_tmp, imsize)\n",
        "            super_img = []\n",
        "            for j in range(num_sentences):\n",
        "                img = images_list[j][i]\n",
        "                # print(img.size())\n",
        "                img = img.view(1, 3, imsize, imsize)\n",
        "                # print(img.size())\n",
        "                super_img.append(img)\n",
        "                # break\n",
        "            super_img = torch.cat(super_img, 0)\n",
        "            vutils.save_image(super_img, savename, nrow=10, normalize=True)\n",
        "\n",
        "    def save_singleimages(self, images, filenames,\n",
        "                          save_dir, split_dir, sentenceID, imsize):\n",
        "        for i in range(images.size(0)):\n",
        "            s_tmp = '%s/single_samples/%s/%s' %\\\n",
        "                (save_dir, split_dir, filenames[i])\n",
        "            folder = s_tmp[:s_tmp.rfind('/')]\n",
        "            if not os.path.isdir(folder):\n",
        "                print('Make a new folder: ', folder)\n",
        "                mkdir_p(folder)\n",
        "\n",
        "            fullpath = '%s_%d_sentence%d.png' % (s_tmp, imsize, sentenceID)\n",
        "            # range from [-1, 1] to [0, 255]\n",
        "            img = images[i].add(1).div(2).mul(255).clamp(0, 255).byte()\n",
        "            ndarr = img.permute(1, 2, 0).data.cpu().numpy()\n",
        "            im = Image.fromarray(ndarr)\n",
        "            im.save(fullpath)\n",
        "\n",
        "    def evaluate(self, split_dir):\n",
        "        if cfg.TRAIN.NET_G == '':\n",
        "            print('Error: the path for morels is not found!')\n",
        "        else:\n",
        "            # Build and load the generator\n",
        "            if split_dir == 'test':\n",
        "                split_dir = 'valid'\n",
        "            netG = G_NET()\n",
        "            netG.apply(weights_init)\n",
        "            netG = torch.nn.DataParallel(netG, device_ids=self.gpus)\n",
        "            print(netG)\n",
        "            # state_dict = torch.load(cfg.TRAIN.NET_G)\n",
        "            state_dict = \\\n",
        "                torch.load(cfg.TRAIN.NET_G,\n",
        "                           map_location=lambda storage, loc: storage)\n",
        "            netG.load_state_dict(state_dict)\n",
        "            print('Load ', cfg.TRAIN.NET_G)\n",
        "\n",
        "            # the path to save generated images\n",
        "            s_tmp = cfg.TRAIN.NET_G\n",
        "            istart = s_tmp.rfind('_') + 1\n",
        "            iend = s_tmp.rfind('.')\n",
        "            iteration = int(s_tmp[istart:iend])\n",
        "            s_tmp = s_tmp[:s_tmp.rfind('/')]\n",
        "            save_dir = '%s/iteration%d' % (s_tmp, iteration)\n",
        "\n",
        "            nz = cfg.GAN.Z_DIM\n",
        "            noise = Variable(torch.FloatTensor(self.batch_size, nz))\n",
        "            if cfg.CUDA:\n",
        "                netG.cuda()\n",
        "                noise = noise.cuda()\n",
        "\n",
        "            # switch to evaluate mode\n",
        "            netG.eval()\n",
        "            for step, data in enumerate(self.data_loader, 0):\n",
        "                imgs, t_embeddings, filenames = data\n",
        "                if cfg.CUDA:\n",
        "                    t_embeddings = Variable(t_embeddings).cuda()\n",
        "                else:\n",
        "                    t_embeddings = Variable(t_embeddings)\n",
        "\n",
        "                embedding_dim = t_embeddings.size(1)\n",
        "                batch_size = imgs[0].size(0)\n",
        "                noise.data.resize_(batch_size, nz)\n",
        "                noise.data.normal_(0, 1)\n",
        "\n",
        "                fake_img_list = []\n",
        "                for i in range(embedding_dim):\n",
        "                    fake_imgs, _, _ = netG(noise, t_embeddings[:, i, :])\n",
        "                    if cfg.TEST.B_EXAMPLE:\n",
        "                        fake_img_list.append(fake_imgs[2].data.cpu())\n",
        "                    else:\n",
        "                        self.save_singleimages(fake_imgs[-1], filenames,\n",
        "                                               save_dir, split_dir, i, 256)\n",
        "    \n",
        "                if cfg.TEST.B_EXAMPLE:\n",
        "                    self.save_superimages(fake_img_list, filenames,\n",
        "                                          save_dir, split_dir, 256)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hkl_PZGWuD5c"
      },
      "source": [
        "class RecipeDataset(data.Dataset):\n",
        "    def __init__(self, \n",
        "                 data_dir='data', \n",
        "                 csv_filename='eda_ru_filtered.csv',\n",
        "                 use_last_image=False,\n",
        "                 base_size=64,\n",
        "                 transform=None, target_transform=None):\n",
        "        self.transform = transform\n",
        "        self.norm = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "        \n",
        "        self.size_transforms = [\n",
        "            transforms.Scale(64),\n",
        "            transforms.Scale(128),     \n",
        "            transforms.Scale(256),               \n",
        "        ]\n",
        "        self.target_transform = target_transform\n",
        "        \n",
        "        self.data_dir = Path(data_dir)\n",
        "        self.csv_filename = csv_filename\n",
        "        self.use_last_image = use_last_image\n",
        "        \n",
        "        self.data = pd.read_csv(self.data_dir / self.csv_filename, usecols=['id', 'images', 'title'])\n",
        "        self.ids = self.data['id'].values\n",
        "        self.images = self.data['images'].values\n",
        "        self.titles = self.data['title'].values\n",
        "        \n",
        "        self.embeddings = self.load_embeddings()\n",
        "\n",
        "    \n",
        "    def load_embeddings(self):\n",
        "\n",
        "        embeddings = []\n",
        "\n",
        "        for idx in self.ids:\n",
        "            title_emb = np.load(f'{self.data_dir}/embeddings/all_recipe/{idx}.npz')['arr_0']\n",
        "            # ingredients_emb = np.load(f'{self.data_dir}/embeddings/ingredients/{idx}.npz')['arr_0']\n",
        "            # steps_emb = np.load(f'{self.data_dir}/embeddings/steps/{idx}.npz')['arr_0']\n",
        "\n",
        "            embeddings.append(\n",
        "                np.concatenate([title_emb], axis=1)\n",
        "            )\n",
        "\n",
        "        return np.array(embeddings)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        #\n",
        "        image_pathes = self.images[idx].split('|')\n",
        "        if self.use_last_image:\n",
        "            img_path = image_pathes[-1]\n",
        "        else:\n",
        "            img_path = random.choice(image_pathes)\n",
        "       \n",
        "        # Загружаем изображение\n",
        "        img = Image.open(self.data_dir / img_path).convert('RGB')\n",
        "        width, height = img.size\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        imgs = []\n",
        "        for size_transform in self.size_transforms:\n",
        "            imgs.append(self.norm(size_transform(img)))\n",
        "        # imgs.append(self.norm(img))\n",
        "\n",
        "\n",
        "        wrong_id = random.randint(0, len(self.images) - 1)\n",
        "\n",
        "        wrong_image_pathes = self.images[wrong_id].split('|')\n",
        "        if self.use_last_image:\n",
        "            wrong_img_path = wrong_image_pathes[-1]\n",
        "        else:\n",
        "            wrong_img_path = random.choice(wrong_image_pathes)\n",
        "       \n",
        "        # Загружаем изображение\n",
        "        wrong_img = Image.open(self.data_dir / wrong_img_path).convert('RGB')\n",
        "        width, height = wrong_img.size\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(wrong_img)\n",
        "        wrong_imgs = []\n",
        "        \n",
        "        for size_transform in self.size_transforms:\n",
        "            wrong_imgs.append(self.norm(size_transform(wrong_img)))\n",
        "        \n",
        "        # ИСПРАВИТЬ - временно для того чтобы проверить работоспособность в целом\n",
        "        emb = self.embeddings[idx, :][0]\n",
        "        \n",
        "        return imgs, wrong_imgs, emb, self.titles[idx]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.ids)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KF4dbmN5f-x",
        "outputId": "15b5f013-7ea0-42e3-8a7b-b89eef4f1dca"
      },
      "source": [
        "imsize = cfg.TREE.BASE_SIZE * (2 ** (cfg.TREE.BRANCH_NUM-1))\n",
        "\n",
        "image_transform = transforms.Compose([\n",
        "        # transforms.Scale(int(imsize * 76 / 64)),\n",
        "        transforms.RandomCrop(imsize),\n",
        "        transforms.RandomHorizontalFlip()])\n",
        "\n",
        "dataset = RecipeDataset(transform=image_transform)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py:280: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
            "  \"please use transforms.Resize instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oth7GtIUyyC2",
        "outputId": "fde44d81-729a-491f-f042-39170568e34e"
      },
      "source": [
        "imsize"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JW4bGctc6deL"
      },
      "source": [
        "dataloader = torch.utils.data.DataLoader(\n",
        "    dataset, batch_size=cfg.TRAIN.BATCH_SIZE, drop_last=True,\n",
        "    shuffle=True, num_workers=cfg.WORKERS)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLSDaypZJLmg"
      },
      "source": [
        "# shutil.rmtree('./Image')\n",
        "# shutil.rmtree('./Log')\n",
        "# shutil.rmtree('./Model')\n",
        "# del algo\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGh6-5XBuGo-"
      },
      "source": [
        "algo = condGANTrainer(f'{drive_path}/stackgan/all_recipe_256', dataloader, imsize)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYX8-1lP6tTp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "628b8807-b5ec-43ad-b59a-2e0197ed816d"
      },
      "source": [
        "algo.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:39: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "netG loaded\n",
            "# of netsD 3\n",
            "inception_model creation\n",
            "after constructor parent INCEPTION_V3\n",
            "after models.inception_v3() call\n",
            "start downloading inception\n",
            "finish downloading inception\n",
            "Load pretrained model from  https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\n",
            "all models on cuda\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1639: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:193: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukWd6BHvTsr2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DF_GAN_all_in_one_128x128.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyBxzZ53Zx_3",
        "outputId": "40cd8e48-88be-4499-9c87-1bc6a91f9cc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Nov  9 10:18:59 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.32.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   62C    P8    11W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KFPeIf7l2vl",
        "outputId": "a6bd058d-4f43-4982-c81c-6b7b198d5b6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        " !pip install fpdf2"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fpdf2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/28/08c70ff4dc9bb1b0d803432a0b89511bff9c53902b9c81c67f9473dd0d39/fpdf2-2.0.6-py2.py3-none-any.whl (71kB)\n",
            "\r\u001b[K     |████▌                           | 10kB 24.3MB/s eta 0:00:01\r\u001b[K     |█████████                       | 20kB 15.6MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 30kB 15.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 40kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 51kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 61kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 71kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 5.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from fpdf2) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fpdf2) (1.18.5)\n",
            "Requirement already satisfied: Pillow<=8,>=4 in /usr/local/lib/python3.6/dist-packages (from fpdf2) (7.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fpdf2) (1.15.0)\n",
            "Installing collected packages: fpdf2\n",
            "Successfully installed fpdf2-2.0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSTwg1N4NOEX"
      },
      "source": [
        "from pathlib import Path\n",
        "import pickle\n",
        "import random\n",
        "from collections import OrderedDict\n",
        "import os\n",
        "\n",
        "from matplotlib.pyplot import imshow\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import torch.nn.functional as F\n",
        "from fpdf import FPDF\n",
        "import platform"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwL9TxOp0zoj",
        "outputId": "316aca39-0882-4676-d89c-e2e0c3ef9476",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "drive_path = '/content/drive/My Drive/text2image'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9Tnj0SvNOEe",
        "outputId": "0828b546-6254-4daa-fd0a-bf3e41968c57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "os.makedirs('data', exist_ok=True)\n",
        "os.makedirs('data/embeddings', exist_ok=True)\n",
        "os.makedirs('/content/drive/My Drive/text2image/fake_images', exist_ok=True)\n",
        "os.makedirs('/content/drive/My Drive/text2image/fake_images/tmp', exist_ok=True)\n",
        "os.makedirs('/content/drive/My Drive/text2image/models', exist_ok=True)\n",
        "if not os.path.exists('GDriveDL.py'):\n",
        "    !wget https://raw.githubusercontent.com/matthuisman/gdrivedl/master/gdrivedl.py -O GDriveDL.py\n",
        "\n",
        "\n",
        "if not os.path.exists('data/eda_ru.zip'): \n",
        "    !python GDriveDL.py https://drive.google.com/file/d/1CNIbj8_OuxQD74zt6JU4BUI8ngctutl9/view?usp=sharing data\n",
        "    !unzip -q data/eda_ru.zip -d data\n",
        "# if not os.path.exists('df_gan.zip'):        \n",
        "#     !python GDriveDL.py https://drive.google.com/open?id=1KKAqwSbHd-_qMpOAjYdbBRCh4M-HbRTH .\n",
        "#     !unzip -q df_gan.zip"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 0 ns, sys: 541 µs, total: 541 µs\n",
            "Wall time: 8.45 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pDmIG_zNqdV"
      },
      "source": [
        "class NetG(nn.Module):\n",
        "    def __init__(self, ngf=64, nz=100):\n",
        "        super(NetG, self).__init__()\n",
        "\n",
        "        self.fc_embedding = nn.Linear(768, 256)\n",
        "\n",
        "        self.ngf = ngf\n",
        "\n",
        "        # layer1输入的是一个100x1x1的随机噪声, 输出尺寸(ngf*8)x4x4\n",
        "        self.fc = nn.Linear(nz, ngf*8*4*4)\n",
        "        self.block0 = G_Block(ngf * 8, ngf * 8)#4x4\n",
        "        self.block1 = G_Block(ngf * 8, ngf * 8)#4x4\n",
        "        self.block2 = G_Block(ngf * 8, ngf * 8)#8x8\n",
        "        self.block3 = G_Block(ngf * 8, ngf * 8)#16x16\n",
        "        self.block4 = G_Block(ngf * 8, ngf * 4)#32x32\n",
        "        # self.block5 = G_Block(ngf * 4, ngf * 2)#64x64\n",
        "        # self.block6 = G_Block(ngf * 2, ngf * 1)#128x128\n",
        "        self.block5 = G_Block(ngf * 4, ngf * 1)\n",
        "\n",
        "        self.conv_img = nn.Sequential(\n",
        "            nn.LeakyReLU(0.2,inplace=True),\n",
        "            nn.Conv2d(ngf, 3, 3, 1, 1),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, c):\n",
        "\n",
        "        c = self.fc_embedding(c)\n",
        "\n",
        "        out = self.fc(x)\n",
        "        out = out.view(x.size(0), 8*self.ngf, 4, 4)\n",
        "        out = self.block0(out,c)\n",
        "\n",
        "        out = F.interpolate(out, scale_factor=2)\n",
        "        out = self.block1(out,c)\n",
        "\n",
        "        out = F.interpolate(out, scale_factor=2)\n",
        "        out = self.block2(out,c)\n",
        "\n",
        "        out = F.interpolate(out, scale_factor=2)\n",
        "        out = self.block3(out,c)\n",
        "\n",
        "        out = F.interpolate(out, scale_factor=2)\n",
        "        out = self.block4(out,c)\n",
        "\n",
        "        out = F.interpolate(out, scale_factor=2)\n",
        "        out = self.block5(out,c)\n",
        "        # out = F.interpolate(out, scale_factor=2)\n",
        "        # out = self.block6(out,c)\n",
        "\n",
        "        out = self.conv_img(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class G_Block(nn.Module):\n",
        "\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(G_Block, self).__init__()\n",
        "\n",
        "        self.learnable_sc = in_ch != out_ch \n",
        "        self.c1 = nn.Conv2d(in_ch, out_ch, 3, 1, 1)\n",
        "        self.c2 = nn.Conv2d(out_ch, out_ch, 3, 1, 1)\n",
        "        self.affine0 = affine(in_ch)\n",
        "        self.affine1 = affine(in_ch)\n",
        "        self.affine2 = affine(out_ch)\n",
        "        self.affine3 = affine(out_ch)\n",
        "        self.gamma = nn.Parameter(torch.zeros(1))\n",
        "        if self.learnable_sc:\n",
        "            self.c_sc = nn.Conv2d(in_ch,out_ch, 1, stride=1, padding=0)\n",
        "\n",
        "    def forward(self, x, y=None):\n",
        "        return self.shortcut(x) + self.gamma * self.residual(x, y)\n",
        "\n",
        "    def shortcut(self, x):\n",
        "        if self.learnable_sc:\n",
        "            x = self.c_sc(x)\n",
        "        return x\n",
        "\n",
        "    def residual(self, x, y=None):\n",
        "        h = self.affine0(x, y)\n",
        "        h = nn.LeakyReLU(0.2,inplace=True)(h)\n",
        "        h = self.affine1(h, y)\n",
        "        h = nn.LeakyReLU(0.2,inplace=True)(h)\n",
        "        h = self.c1(h)\n",
        "        \n",
        "        h = self.affine2(h, y)\n",
        "        h = nn.LeakyReLU(0.2,inplace=True)(h)\n",
        "        h = self.affine3(h, y)\n",
        "        h = nn.LeakyReLU(0.2,inplace=True)(h)\n",
        "        return self.c2(h)\n",
        "\n",
        "\n",
        "\n",
        "class affine(nn.Module):\n",
        "\n",
        "    def __init__(self, num_features):\n",
        "        super(affine, self).__init__()\n",
        "\n",
        "        self.fc_gamma = nn.Sequential(OrderedDict([\n",
        "            ('linear1',nn.Linear(256, 256)),\n",
        "            ('relu1',nn.ReLU(inplace=True)),\n",
        "            ('linear2',nn.Linear(256, num_features)),\n",
        "            ]))\n",
        "        self.fc_beta = nn.Sequential(OrderedDict([\n",
        "            ('linear1',nn.Linear(256, 256)),\n",
        "            ('relu1',nn.ReLU(inplace=True)),\n",
        "            ('linear2',nn.Linear(256, num_features)),\n",
        "            ]))\n",
        "        self._initialize()\n",
        "\n",
        "    def _initialize(self):\n",
        "        nn.init.zeros_(self.fc_gamma.linear2.weight.data)\n",
        "        nn.init.ones_(self.fc_gamma.linear2.bias.data)\n",
        "        nn.init.zeros_(self.fc_beta.linear2.weight.data)\n",
        "        nn.init.zeros_(self.fc_beta.linear2.bias.data)\n",
        "\n",
        "    def forward(self, x, y=None):\n",
        "\n",
        "        weight = self.fc_gamma(y)\n",
        "        bias = self.fc_beta(y)        \n",
        "\n",
        "        if weight.dim() == 1:\n",
        "            weight = weight.unsqueeze(0)\n",
        "        if bias.dim() == 1:\n",
        "            bias = bias.unsqueeze(0)\n",
        "\n",
        "        size = x.size()\n",
        "        weight = weight.unsqueeze(-1).unsqueeze(-1).expand(size)\n",
        "        bias = bias.unsqueeze(-1).unsqueeze(-1).expand(size)\n",
        "        return weight * x + bias\n",
        "\n",
        "\n",
        "class D_GET_LOGITS(nn.Module):\n",
        "    def __init__(self, ndf):\n",
        "        super(D_GET_LOGITS, self).__init__()\n",
        "        self.df_dim = ndf\n",
        "        self.fc_embedding = nn.Linear(768, 256)\n",
        "\n",
        "        self.joint_conv = nn.Sequential(\n",
        "            nn.Conv2d(ndf * 16+256, ndf * 2, 3, 1, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2,inplace=True),\n",
        "            nn.Conv2d(ndf * 2, 1, 4, 1, 0, bias=False),\n",
        "        )\n",
        "\n",
        "    def forward(self, out, y):\n",
        "\n",
        "        y = self.fc_embedding(y)\n",
        "        \n",
        "        y = y.view(-1, 256, 1, 1)\n",
        "        y = y.repeat(1, 1, 4, 4)\n",
        "        h_c_code = torch.cat((out, y), 1)\n",
        "        out = self.joint_conv(h_c_code)\n",
        "        return out\n",
        "\n",
        "\n",
        "class NetD(nn.Module):\n",
        "    def __init__(self, ndf):\n",
        "        super(NetD, self).__init__()\n",
        "\n",
        "        self.conv_img = nn.Conv2d(3, ndf, 3, 1, 1)#128\n",
        "        self.block0 = resD(ndf * 1, ndf * 2)#64\n",
        "        self.block1 = resD(ndf * 2, ndf * 4)#32\n",
        "        self.block2 = resD(ndf * 4, ndf * 8)#16\n",
        "        self.block3 = resD(ndf * 8, ndf * 16)#8\n",
        "        self.block4 = resD(ndf * 16, ndf * 16)#4\n",
        "        self.block5 = resD(ndf * 16, ndf * 16)#4\n",
        "\n",
        "        self.COND_DNET = D_GET_LOGITS(ndf)\n",
        "\n",
        "    def forward(self,x):\n",
        "        \n",
        "        out = self.conv_img(x)\n",
        "        out = self.block0(out)\n",
        "        out = self.block1(out)\n",
        "        out = self.block2(out)\n",
        "        out = self.block3(out)\n",
        "        out = self.block4(out)\n",
        "        # out = self.block5(out)\n",
        "\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class resD(nn.Module):\n",
        "    def __init__(self, fin, fout, downsample=True):\n",
        "        super().__init__()\n",
        "        self.downsample = downsample\n",
        "        self.learned_shortcut = (fin != fout)\n",
        "        self.conv_r = nn.Sequential(\n",
        "            nn.Conv2d(fin, fout, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            \n",
        "            nn.Conv2d(fout, fout, 3, 1, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "\n",
        "        self.conv_s = nn.Conv2d(fin,fout, 1, stride=1, padding=0)\n",
        "        self.gamma = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "    def forward(self, x, c=None):\n",
        "        return self.shortcut(x)+self.gamma*self.residual(x)\n",
        "\n",
        "    def shortcut(self, x):\n",
        "        if self.learned_shortcut:\n",
        "            x = self.conv_s(x)\n",
        "        if self.downsample:\n",
        "            return F.avg_pool2d(x, 2)\n",
        "        return x\n",
        "\n",
        "    def residual(self, x):\n",
        "        return self.conv_r(x)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaKUwBDoNOEl"
      },
      "source": [
        "### 1) Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gp0WqatPNOEm"
      },
      "source": [
        "class RecipeDataset(data.Dataset):\n",
        "    def __init__(self, \n",
        "                 data_dir='data', \n",
        "                 csv_filename='eda_ru_filtered.csv',\n",
        "                 use_last_image=False,\n",
        "                 base_size=64,\n",
        "                 transform=None, target_transform=None):\n",
        "        self.transform = transform\n",
        "        self.norm = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "        self.target_transform = target_transform\n",
        "        \n",
        "        self.data_dir = Path(data_dir)\n",
        "        self.csv_filename = csv_filename\n",
        "        self.use_last_image = use_last_image\n",
        "        \n",
        "        self.data = pd.read_csv(self.data_dir / self.csv_filename, usecols=['id', 'images', 'title'])\n",
        "        self.ids = self.data['id'].values\n",
        "        self.images = self.data['images'].values\n",
        "        self.titles = self.data['title'].values\n",
        "        \n",
        "        self.embeddings = self.load_embeddings()\n",
        "\n",
        "    \n",
        "    def load_embeddings(self):\n",
        "\n",
        "        embeddings = []\n",
        "\n",
        "        for idx in self.ids:\n",
        "            title_emb = np.load(f'{self.data_dir}/embeddings/title/{idx}.npz')['arr_0']\n",
        "            # ingredients_emb = np.load(f'{self.data_dir}/embeddings/ingredients/{idx}.npz')['arr_0']\n",
        "            # steps_emb = np.load(f'{self.data_dir}/embeddings/steps/{idx}.npz')['arr_0']\n",
        "\n",
        "            embeddings.append(\n",
        "                np.concatenate([title_emb], axis=1)\n",
        "            )\n",
        "\n",
        "        return np.array(embeddings)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        #\n",
        "        image_pathes = self.images[idx].split('|')\n",
        "        if self.use_last_image:\n",
        "            img_path = image_pathes[-1]\n",
        "        else:\n",
        "            img_path = random.choice(image_pathes)\n",
        "       \n",
        "        # Загружаем изображение\n",
        "        img = Image.open(self.data_dir / img_path).convert('RGB')\n",
        "        width, height = img.size\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        imgs = []\n",
        "        imgs.append(self.norm(img))\n",
        "        \n",
        "        # ИСПРАВИТЬ - временно для того чтобы проверить работоспособность в целом\n",
        "        emb = self.embeddings[idx, :][0]\n",
        "        \n",
        "        return imgs, emb, self.titles[idx]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.ids)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5eWxLRrNOEp"
      },
      "source": [
        "# embeddings = 'RuBERT_mean_embeddings_long'\n",
        "# embeddings_type = 'whole_recipe'\n",
        "# train_data = RecipeDataset()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5ruvDXVNOEr"
      },
      "source": [
        "#### Посмотрим что получилось:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSylcA_DNOEr",
        "outputId": "dedff564-bed7-41be-e8ce-98be0035e025",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# print(train_data.ids[:5])\n",
        "# print(train_data.recipes[:5])\n",
        "# print(train_data.filenames[:5])\n",
        "# print(len(train_data))\n",
        "# imshow(train_data[1][0][0].numpy().transpose(1, 2, 0))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Слоеные булки' 'Итальянское персиковое мороженое (Gelato)'\n",
            " 'Итальянское мороженое с лимонной цедрой (Gelato)'\n",
            " 'Закуска из курицы в листьях салата' 'Маринованные куриные ломтики']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoXn6sHUNOEw"
      },
      "source": [
        "## 2) Обучение"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uRiK_leNOEw",
        "outputId": "5a020539-6ad5-421e-f0e2-85ef58df79db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "seed = 100\n",
        "print(\"seed now is : \", seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device('cpu')\n",
        "cudnn.benchmark = True"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "seed now is :  100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swNJBDvTNOE0",
        "outputId": "ea1af680-ca4f-4e02-bf64-45506ea43d47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "device"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfOT0k0lNOE2"
      },
      "source": [
        "#### Config:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZbbtxOjNOE3"
      },
      "source": [
        "config = {}\n",
        "\n",
        "config['MODEL_NAME'] = 'eda_ru_tuned_bert_title_emb_only_128'\n",
        "\n",
        "config['CUDA'] = True\n",
        "config['WORKERS'] = 4\n",
        "\n",
        "config['loss'] = 'hinge'\n",
        "config['BASE_SIZE'] = 64\n",
        "\n",
        "# config['DATASET'] = {}\n",
        "# config['DATASET']['EMBEDDINGS_FILE'] = 'RuBERT_mean_embeddings_long'\n",
        "# config['DATASET']['EMBEDDINGS_TYPE'] = 'whole_recipe'\n",
        "\n",
        "\n",
        "config['IMAGE_SIZE'] = 128\n",
        "config['TRAIN'] = {}\n",
        "config['TRAIN']['BATCH_SIZE'] = 16\n",
        "config['TRAIN']['MAX_EPOCH'] = 512\n",
        "config['TRAIN']['SNAPSHOT_INTERVAL'] = 2000\n",
        "config['TRAIN']['DISCRIMINATOR_LR'] = 2e-4\n",
        "config['TRAIN']['GENERATOR_LR'] = 2e-4\n",
        "config['TRAIN']['ENCODER_LR'] = 2e-4\n",
        "# config['TRAIN']['RNN_GRAD_CLIP'] = 0.25\n",
        "# config['TRAIN']['FLAG'] = True\n",
        "# config['TRAIN']['NET_E'] = ''\n",
        "# config['TRAIN']['NET_G'] = ''\n",
        "# config['TRAIN']['B_NET_D'] = True\n",
        "config['TRAIN']['NF'] = 32\n",
        "config['TRAIN']['SMOOTH'] = {}\n",
        "config['TRAIN']['SMOOTH']['GAMMA1'] = 5.0\n",
        "config['TRAIN']['SMOOTH']['GAMMA1'] = 10.0\n",
        "config['TRAIN']['SMOOTH']['GAMMA1'] = 5.0\n",
        "config['TRAIN']['SMOOTH']['GAMMA1'] = 1.0\n",
        "\n",
        "config['GAN'] = {}\n",
        "config['GAN']['DF_DIM'] = 64\n",
        "config['GAN']['GF_DIM'] = 128\n",
        "config['GAN']['Z_DIM'] = 100\n",
        "config['GAN']['CONDITION_DIM'] = 100\n",
        "config['GAN']['R_NUM'] = 2\n",
        "config['GAN']['B_ATTENTION'] = True\n",
        "config['GAN']['B_DCGAN'] = True"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwP8-C08NOE6",
        "outputId": "21e452df-36fd-4b20-d955-3fd0b53676d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# dataset and dataloader\n",
        "\n",
        "# image_transform = transforms.Compose([\n",
        "#     transforms.Resize(int(config['IMAGE_SIZE'] * 76 / 64)),\n",
        "#     transforms.RandomCrop(config['IMAGE_SIZE']),\n",
        "#     transforms.RandomHorizontalFlip()])\n",
        "\n",
        "image_transform = transforms.Compose([\n",
        "    transforms.Resize(int(config['IMAGE_SIZE']))\n",
        "    ])\n",
        "   \n",
        "dataset = RecipeDataset(transform=image_transform)\n",
        "\n",
        "print(len(dataset))\n",
        "assert dataset\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    dataset, batch_size=config['TRAIN']['BATCH_SIZE'], drop_last=True,\n",
        "    shuffle=True, num_workers=config['WORKERS'])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30091\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I79bOCvpNOE8"
      },
      "source": [
        "def prepare_data(data):\n",
        "    imgs, embds, titles = data\n",
        "\n",
        "    real_imgs = []\n",
        "    for i in range(len(imgs)):\n",
        "        if config['CUDA']:\n",
        "            real_imgs.append(Variable(imgs[i]).cuda())\n",
        "        else:\n",
        "            real_imgs.append(Variable(imgs[i]))\n",
        "\n",
        "    if config['CUDA']:\n",
        "        embds = Variable(embds).cuda()\n",
        "    else:\n",
        "        embds = Variable(embds)\n",
        "\n",
        "    return [real_imgs, embds, titles]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Am46ap2m2Xk"
      },
      "source": [
        "def save_pdf_images(data, titles, path, epoch, step):\n",
        "    for idx in range(data.shape[0]):\n",
        "        image = data[idx]\n",
        "        path_image = f'{path}/tmp/{idx}.png' \n",
        "        vutils.save_image(image, path_image, normalize=True)\n",
        "    document = FPDF()\n",
        "\n",
        "    if platform.system() == 'Windows':\n",
        "        document.add_font('current_font', '', r\"c:\\WINDOWS\\Fonts\\arial.ttf\", uni=True)\n",
        "    if platform.system() == 'Linux':\n",
        "        document.add_font('current_font','', '/usr/share/fonts/truetype/liberation/LiberationMono-Regular.ttf', uni=True)\n",
        "\n",
        "    document.set_font('current_font', size=6)\n",
        "\n",
        "    startPoint = (6, 6)\n",
        "    image_size = 60\n",
        "    block_size = 70\n",
        "    image_per_line = 3\n",
        "    line_per_page = 4\n",
        "\n",
        "    for image_idx in range(data.shape[0]):\n",
        "        if image_idx % (line_per_page * image_per_line) == 0:\n",
        "            document.add_page()\n",
        "        elif image_idx % image_per_line == 0 and image_idx > 0:\n",
        "            document.ln()\n",
        "      \n",
        "        index_in_page = image_idx % (line_per_page * image_per_line)\n",
        "        line = index_in_page // image_per_line\n",
        "        idx = index_in_page % image_per_line\n",
        "\n",
        "        document.text(idx * block_size + startPoint[0], line * block_size + startPoint[1], titles[image_idx])\n",
        "        document.image(f'{path}/tmp/{image_idx}.png', x = idx * block_size + startPoint[0], y = line * block_size + startPoint[1] + 3, w = image_size, h = image_size)\n",
        "     \n",
        "    document.output(f'{path}/{config[\"MODEL_NAME\"]}_{epoch}_{step}.pdf')\n",
        "    "
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pv0kIEAqNOE-"
      },
      "source": [
        "def train(dataloader, netG, netD, optimizerG, optimizerD, state_epoch, batch_size, device):\n",
        "    fake_images = Path(f'{drive_path}/fake_images')\n",
        "    fake_images.mkdir(exist_ok=True)\n",
        "    fake_images = fake_images / f'{config[\"MODEL_NAME\"]}'\n",
        "    fake_images.mkdir(exist_ok=True)\n",
        "    (fake_images / 'tmp').mkdir(exist_ok=True)\n",
        "\n",
        "    for epoch in range(state_epoch + 1, config['TRAIN']['MAX_EPOCH'] + 1):\n",
        "        for step, data in enumerate(dataloader, 0):\n",
        "    \n",
        "            imags, sent_emb, titles = prepare_data(data)\n",
        "#             hidden = text_encoder.init_hidden(batch_size)\n",
        "#             # words_embs: batch_size x nef x seq_len\n",
        "#             # sent_emb: batch_size x nef\n",
        "#             words_embs, sent_emb = text_encoder(captions, cap_lens, hidden)\n",
        "#             words_embs, sent_emb = words_embs.detach(), sent_emb.detach()\n",
        "\n",
        "            imgs=imags[0].to(device)\n",
        "            real_features = netD(imgs)\n",
        "            output = netD.COND_DNET(real_features, sent_emb)\n",
        "            errD_real = torch.nn.ReLU()(1.0 - output).mean()\n",
        "\n",
        "            output = netD.COND_DNET(real_features[:(batch_size - 1)], sent_emb[1:batch_size])\n",
        "            errD_mismatch = torch.nn.ReLU()(1.0 + output).mean()\n",
        "\n",
        "            # synthesize fake images\n",
        "            noise = torch.randn(batch_size, 100)\n",
        "            noise=noise.to(device)\n",
        "            fake = netG(noise,sent_emb)  \n",
        "            \n",
        "            # G does not need update with D\n",
        "            fake_features = netD(fake.detach()) \n",
        "\n",
        "            errD_fake = netD.COND_DNET(fake_features,sent_emb)\n",
        "            errD_fake = torch.nn.ReLU()(1.0 + errD_fake).mean()          \n",
        "\n",
        "            errD = errD_real + (errD_fake + errD_mismatch)/2.0\n",
        "            optimizerD.zero_grad()\n",
        "            optimizerG.zero_grad()\n",
        "            errD.backward()\n",
        "            optimizerD.step()\n",
        "\n",
        "            #MA-GP\n",
        "            interpolated = (imgs.data).requires_grad_(True)\n",
        "            sent_inter = (sent_emb.data).requires_grad_(True)\n",
        "            features = netD(interpolated)\n",
        "            out = netD.COND_DNET(features,sent_inter)\n",
        "            grads = torch.autograd.grad(outputs=out,\n",
        "                                    inputs=(interpolated,sent_inter),\n",
        "                                    grad_outputs=torch.ones(out.size()).cuda(),\n",
        "                                    retain_graph=True,\n",
        "                                    create_graph=True,\n",
        "                                    only_inputs=True)\n",
        "            grad0 = grads[0].view(grads[0].size(0), -1)\n",
        "            grad1 = grads[1].view(grads[1].size(0), -1)\n",
        "            grad = torch.cat((grad0,grad1),dim=1)                        \n",
        "            grad_l2norm = torch.sqrt(torch.sum(grad ** 2, dim=1))\n",
        "            d_loss_gp = torch.mean((grad_l2norm) ** 6)\n",
        "            d_loss = 2.0 * d_loss_gp\n",
        "            optimizerD.zero_grad()\n",
        "            optimizerG.zero_grad()\n",
        "            d_loss.backward()\n",
        "            optimizerD.step()\n",
        "            \n",
        "            # update G\n",
        "            features = netD(fake)\n",
        "            output = netD.COND_DNET(features,sent_emb)\n",
        "            errG = - output.mean()\n",
        "            optimizerG.zero_grad()\n",
        "            optimizerD.zero_grad()\n",
        "            errG.backward()\n",
        "            optimizerG.step()\n",
        "\n",
        "            if step % 50 == 0:\n",
        "                print('[%d/%d][%d/%d] Loss_D: %.3f Loss_G %.3f'\n",
        "                    % (epoch, config['TRAIN']['MAX_EPOCH'], step, len(dataloader), errD.item(), errG.item()))\n",
        "\n",
        "                save_pdf_images(fake.data, titles, str(fake_images), epoch, step)\n",
        "\n",
        "        if epoch % 1 == 0:\n",
        "            path_netG = f'{drive_path}/models/{config[\"MODEL_NAME\"]}_netG_{epoch}.pth' \n",
        "            path_netD = f'{drive_path}/models/{config[\"MODEL_NAME\"]}_netD_{epoch}.pth' \n",
        "            torch.save(netG.state_dict(), path_netG)\n",
        "            torch.save(netD.state_dict(), path_netD)      "
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40vbxeneNOFA"
      },
      "source": [
        "netG = NetG(ngf=config['TRAIN']['NF'], nz=100)\n",
        "netD = NetD(ndf=config['TRAIN']['NF'])\n",
        "state_epoch=0\n",
        "\n",
        "\n",
        "# load_epoch = 81\n",
        "# path_netG = f'{drive_path}/models/{config[\"MODEL_NAME\"]}_netG_{load_epoch}.pth' \n",
        "# path_netD = f'{drive_path}/models/{config[\"MODEL_NAME\"]}_netD_{load_epoch}.pth' \n",
        "# netG.load_state_dict(torch.load(path_netG))\n",
        "# netD.load_state_dict(torch.load(path_netD))\n",
        "# state_epoch = load_epoch\n",
        "\n",
        "\n",
        "netG.to(device)\n",
        "netD.to(device)\n",
        "optimizerG = torch.optim.Adam(netG.parameters(), lr=0.0001, betas=(0.0, 0.9))\n",
        "optimizerD = torch.optim.Adam(netD.parameters(), lr=0.0004, betas=(0.0, 0.9))"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NILpHmENOFC",
        "outputId": "4232e864-d680-4351-b41e-caf009248896",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "train(dataloader, netG, netD, optimizerG, optimizerD, state_epoch, config['TRAIN']['BATCH_SIZE'], device)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1/512][0/1880] Loss_D: 1.998 Loss_G 0.030\n",
            "[1/512][50/1880] Loss_D: 1.682 Loss_G 1.321\n",
            "[1/512][100/1880] Loss_D: 1.386 Loss_G 0.827\n",
            "[1/512][150/1880] Loss_D: 1.751 Loss_G 0.141\n",
            "[1/512][200/1880] Loss_D: 1.899 Loss_G 0.362\n",
            "[1/512][250/1880] Loss_D: 2.009 Loss_G 0.202\n",
            "[1/512][300/1880] Loss_D: 1.952 Loss_G 0.828\n",
            "[1/512][350/1880] Loss_D: 1.777 Loss_G 0.580\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-0ba60c327d8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizerG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizerD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TRAIN'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'BATCH_SIZE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-67-df4b87361a38>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataloader, netG, netD, optimizerG, optimizerD, state_epoch, batch_size, device)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0moptimizerD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0merrG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0moptimizerG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    117\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m                    )\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2CjVIWZaF0t",
        "outputId": "eeabc570-a5bc-453a-88d0-6d8f8de417f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dataset[1][1][0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2304,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yx4w9KhOnxMu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}